{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c7cc7ae",
   "metadata": {},
   "source": [
    "# Swaption prediction using a Hybrid Quantum Reservoir Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0750c8-ccf4-4767-9346-ce4c92af543f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11783,
     "status": "ok",
     "timestamp": 1764456060639,
     "user": {
      "displayName": "Sonya Kukulina",
      "userId": "10766522173340573677"
     },
     "user_tz": -60
    },
    "id": "7d0750c8-ccf4-4767-9346-ce4c92af543f",
    "outputId": "0305a5da-d6fa-4aab-a65c-d24078c3a5e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: merlinquantum in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (0.2.3)\n",
      "Requirement already satisfied: torch in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: seaborn in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: perceval-quandela>=0.13.1 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from merlinquantum) (1.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from seaborn) (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: tabulate~=0.9 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from perceval-quandela>=0.13.1->merlinquantum) (0.9.0)\n",
      "Requirement already satisfied: exqalibur~=1.1.0 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from perceval-quandela>=0.13.1->merlinquantum) (1.1.1)\n",
      "Requirement already satisfied: multipledispatch<2 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from perceval-quandela>=0.13.1->merlinquantum) (1.0.0)\n",
      "Requirement already satisfied: protobuf>=3.20.3 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from perceval-quandela>=0.13.1->merlinquantum) (6.33.1)\n",
      "Requirement already satisfied: drawsvg>=2.0 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from perceval-quandela>=0.13.1->merlinquantum) (2.4.0)\n",
      "Requirement already satisfied: requests<3 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from perceval-quandela>=0.13.1->merlinquantum) (2.32.5)\n",
      "Requirement already satisfied: latexcodec<4 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from perceval-quandela>=0.13.1->merlinquantum) (3.0.1)\n",
      "Requirement already satisfied: platformdirs<5 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from perceval-quandela>=0.13.1->merlinquantum) (4.5.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from perceval-quandela>=0.13.1->merlinquantum) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from requests<3->perceval-quandela>=0.13.1->merlinquantum) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from requests<3->perceval-quandela>=0.13.1->merlinquantum) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from requests<3->perceval-quandela>=0.13.1->merlinquantum) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from requests<3->perceval-quandela>=0.13.1->merlinquantum) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\sonya\\anaconda3\\envs\\pushq\\lib\\site-packages (from tqdm->perceval-quandela>=0.13.1->merlinquantum) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install merlinquantum torch scikit-learn pandas numpy seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "095ad269-1070-46b5-8a64-a4c1ee619a03",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1764456060663,
     "user": {
      "displayName": "Sonya Kukulina",
      "userId": "10766522173340573677"
     },
     "user_tz": -60
    },
    "id": "095ad269-1070-46b5-8a64-a4c1ee619a03"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "import merlin\n",
    "from merlin import QuantumLayer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import perceval as pcvl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933d9408",
   "metadata": {},
   "source": [
    "# 1) Hyperparameters and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d93d8c33-b329-48f1-961e-97f2e986245d",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1764456060666,
     "user": {
      "displayName": "Sonya Kukulina",
      "userId": "10766522173340573677"
     },
     "user_tz": -60
    },
    "id": "d93d8c33-b329-48f1-961e-97f2e986245d"
   },
   "outputs": [],
   "source": [
    "# Data Paths & Preprocessing\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "TRAIN_FILE = \"train.xlsx\"\n",
    "\n",
    "INCOMPLETE_PATH = 'price.xlsx'\n",
    "\n",
    "# Model Hyperparameters\n",
    "N_MODES =  8               # Number of optical modes (qubits equivalent)\n",
    "N_PHOTONS = 4              # Number of photons\n",
    "BATCH_SIZE = 32            # batch sizing data for training\n",
    "EPOCHS = 100               # Number of Epochs for training loop\n",
    "LEARNING_RATE = 0.00005    # learning rate for training algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d10e870-6f5a-4c3d-be7a-4eaae24497ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8837,
     "status": "ok",
     "timestamp": 1764456069508,
     "user": {
      "displayName": "Sonya Kukulina",
      "userId": "10766522173340573677"
     },
     "user_tz": -60
    },
    "id": "4d10e870-6f5a-4c3d-be7a-4eaae24497ae",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "c546ef51-0d4c-42ab-ecd5-ae33b05dbba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset loaded.\n",
      "Columns: 224 swaptions found.\n"
     ]
    }
   ],
   "source": [
    "#DATA LOADING and indentification\n",
    "df_train = pd.read_excel(TRAIN_FILE)\n",
    "df_train[\"Date\"] = pd.to_datetime(df_train[\"Date\"], format=\"%d/%m/%Y\")\n",
    "\n",
    "# Identify swaption columns\n",
    "swaption_cols = [c for c in df_train.columns if c.startswith(\"Tenor\")]\n",
    "\n",
    "print(\"Training dataset loaded.\")\n",
    "print(\"Columns:\", len(swaption_cols), \"swaptions found.\")\n",
    "\n",
    "# Data Sampling\n",
    "df_sample = pd.read_excel(INCOMPLETE_PATH)\n",
    "df_sample[\"Date\"] = pd.to_datetime(df_sample[\"Date\"], format=\"%d/%m/%Y\")\n",
    "\n",
    "def parse_tenor_maturity(col):\n",
    "    m = re.search(r\"Tenor\\s*:\\s*([0-9.]+);\\s*Maturity\\s*:\\s*([0-9.]+)\", col)\n",
    "    return float(m.group(1)), float(m.group(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd2c6bf",
   "metadata": {},
   "source": [
    "# 2) Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d8f60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from train.xlsx...\n",
      "Data shape: (494, 224) (Days, Surface Points)\n",
      "Training samples: 394\n",
      "Testing samples: 99\n"
     ]
    }
   ],
   "source": [
    "#Data preparation\n",
    "TRAIN_FILE = \"train.xlsx\"\n",
    "SAMPLE_FILE = \"test_template.xlsx\"\n",
    "\n",
    "# SWAPTION DATASET\n",
    "class SwaptionDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "def load_and_process_data(filepath):\n",
    "    print(f\"Loading data from {filepath}...\")\n",
    "    df = pd.read_excel(filepath)\n",
    "\n",
    "    # Parse dates\n",
    "    df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
    "    df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "    # Extract features (all columns except Date)\n",
    "    feature_cols = [c for c in df.columns if c != 'Date']\n",
    "    data_values = df[feature_cols].values\n",
    "\n",
    "    print(f\"Data shape: {data_values.shape} (Days, Surface Points)\")\n",
    "\n",
    "    # Create Input (X) and Target (y)\n",
    "    X = data_values[:-1]\n",
    "    y = data_values[1:]\n",
    "\n",
    "    # Normalisation of the data\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    y_scaled = scaler.transform(y)\n",
    "\n",
    "    return X_scaled, y_scaled, scaler, len(feature_cols)\n",
    "\n",
    "# Load training data\n",
    "if not os.path.exists(TRAIN_FILE):\n",
    "    raise FileNotFoundError(f\"Could not find {TRAIN_FILE}. Please ensure it is in the folder.\")\n",
    "\n",
    "X_all, y_all, scaler, INPUT_DIM = load_and_process_data(TRAIN_FILE)\n",
    "\n",
    "# Split into Train and Test (20% test size)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(SwaptionDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(SwaptionDataset(X_test, y_test), batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0de3f1",
   "metadata": {},
   "source": [
    "# 3) Model Generation (Linear, PCA, Hybrid-Quantum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d473900-8e13-4126-8de3-0b05fcacf01d",
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1764456069549,
     "user": {
      "displayName": "Sonya Kukulina",
      "userId": "10766522173340573677"
     },
     "user_tz": -60
    },
    "id": "1d473900-8e13-4126-8de3-0b05fcacf01d"
   },
   "outputs": [],
   "source": [
    "# Baseline Linear Model (not used here)\n",
    "class LinearModelBaseline(nn.Module):\n",
    "    def __init__(self, image_size, num_classes=10):\n",
    "        super(LinearModelBaseline, self).__init__()\n",
    "        self.image_size = image_size\n",
    "        self.classifier = nn.Linear(image_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Data is already flattened\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddec9661-42a4-462e-afef-abfc25479a32",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1764456069584,
     "user": {
      "displayName": "Sonya Kukulina",
      "userId": "10766522173340573677"
     },
     "user_tz": -60
    },
    "id": "ddec9661-42a4-462e-afef-abfc25479a32"
   },
   "outputs": [],
   "source": [
    "# LinearModel with PCA\n",
    "class LinearModelPCA(nn.Module):\n",
    "    def __init__(self, n_swaps, pca_components):\n",
    "        super(LinearModelPCA, self).__init__()\n",
    "        self.n_swaps = n_swaps\n",
    "        self.pca_components = pca_components\n",
    "\n",
    "        # Classical part\n",
    "        self.classifier = nn.Linear(\n",
    "            n_swaps+pca_components, n_swaps\n",
    "        )\n",
    "    def forward(self, x, x_pca):\n",
    "        # Data is already flattened, just concatenate\n",
    "        combined_features = torch.cat((x, x_pca), dim=1)\n",
    "        output = self.classifier(combined_features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da23257a-40ef-483b-aa09-5216e566220b",
   "metadata": {
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1764456093537,
     "user": {
      "displayName": "Sonya Kukulina",
      "userId": "10766522173340573677"
     },
     "user_tz": -60
    },
    "id": "da23257a-40ef-483b-aa09-5216e566220b"
   },
   "outputs": [],
   "source": [
    "# QuantumReservoir class - quantum layer applying on pca\n",
    "class QuantumReservoir(nn.Module):\n",
    "    def __init__(self, n_swaps, pca_components, n_modes, n_photons):\n",
    "        super(QuantumReservoir, self).__init__()\n",
    "        self.n_swaps = n_swaps\n",
    "        self.pca_components = pca_components\n",
    "        self.n_modes = n_modes\n",
    "        self.n_photons = n_photons\n",
    "\n",
    "        # Quantum part (non-trainable reservoir)\n",
    "        self.quantum_layer = self._create_quantum_reservoir(\n",
    "            pca_components, n_modes, n_photons\n",
    "        )\n",
    "\n",
    "        q_dim = self.quantum_layer.output_size\n",
    "\n",
    "        # Classical part\n",
    "        self.classifier = nn.Linear(\n",
    "            n_swaps+q_dim, n_swaps\n",
    "        )\n",
    "\n",
    "        print(f\"\\nQuantum Reservoir Created:\")\n",
    "        print(f\"  Input size (PCA components): {pca_components}\")\n",
    "        print(f\"  Quantum output size: {self.quantum_layer.output_size}\")\n",
    "        print(f\"  Total features to classifier: {n_swaps + self.quantum_layer.output_size}\")\n",
    "\n",
    "    def _create_quantum_reservoir(self, input_size, n_modes, n_photons):\n",
    "        \"\"\"Create quantum layer with Series circuit in reservoir mode.\"\"\"\n",
    "\n",
    "        builder = merlin.CircuitBuilder(n_modes=n_modes)\n",
    "        builder.add_angle_encoding()\n",
    "        builder.add_angle_encoding()\n",
    "        builder.add_superpositions(depth=1)\n",
    "        builder.add_entangling_layer(trainable=False)\n",
    "        builder.add_superpositions(depth=1)\n",
    "        builder.add_angle_encoding()\n",
    "        builder.add_angle_encoding()\n",
    "        circuit = builder.circuit\n",
    "\n",
    "\n",
    "        # Create quantum layer\n",
    "        quantum_layer = QuantumLayer(\n",
    "            input_size=input_size,\n",
    "            builder=builder,\n",
    "            n_photons=n_photons,\n",
    "            no_bunching=False,\n",
    "            measurement_strategy=merlin.MeasurementStrategy.PROBABILITIES,\n",
    "            )\n",
    "\n",
    "        return quantum_layer\n",
    "\n",
    "    def forward(self, x, x_pca):\n",
    "        # Process the PCA-reduced input through quantum layer\n",
    "        quantum_output = self.quantum_layer(x_pca)\n",
    "\n",
    "        # Concatenate original features with quantum output\n",
    "        combined_features = torch.cat((x, quantum_output), dim=1)\n",
    "\n",
    "        # Final classification\n",
    "        output = self.classifier(combined_features)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f6695a4-f131-4496-8db3-777057f1614c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1849,
     "status": "ok",
     "timestamp": 1764456095389,
     "user": {
      "displayName": "Sonya Kukulina",
      "userId": "10766522173340573677"
     },
     "user_tz": -60
    },
    "id": "7f6695a4-f131-4496-8db3-777057f1614c",
    "outputId": "592e5dfe-ada5-4801-ac56-13d079253353"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.7495e+00,  4.5251e-01,  1.0974e-01,  ...,  4.8383e-05,\n",
      "         -6.2104e-06,  3.2952e-05],\n",
      "        [-4.2649e+00,  4.8458e-01,  1.5561e-01,  ...,  3.4553e-05,\n",
      "         -7.5313e-06,  1.7492e-05],\n",
      "        [-4.4656e+00,  4.4418e-01,  1.0201e-01,  ...,  3.5434e-05,\n",
      "         -1.1094e-05,  1.8261e-05],\n",
      "        ...,\n",
      "        [-2.4229e+00, -7.8226e-01, -6.0902e-01,  ...,  2.9609e-05,\n",
      "         -1.2371e-05, -1.4038e-05],\n",
      "        [-2.1843e+00, -5.8874e-01, -6.3556e-01,  ...,  2.9316e-05,\n",
      "         -3.4132e-06, -1.8664e-05],\n",
      "        [-2.7844e+00, -4.9423e-01, -7.1268e-01,  ...,  6.2861e-05,\n",
      "         -9.6663e-06, -2.1981e-05]])\n"
     ]
    }
   ],
   "source": [
    "n_components=N_MODES*4\n",
    "\n",
    "# train PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# Note: Data is already flattened\n",
    "X_train_flat = X_train\n",
    "X_test_flat = X_test\n",
    "\n",
    "pca.fit(X_train_flat)\n",
    "X_train_pca = torch.FloatTensor(pca.transform(X_train_flat))\n",
    "X_test_pca = torch.FloatTensor(pca.transform(X_test_flat))\n",
    "print(X_train_pca)\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train_flat)\n",
    "X_test_tensor = torch.FloatTensor(X_test_flat)\n",
    "y_test_tensor = torch.FloatTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a7d1f26-92bb-4557-b748-e6acf787e94c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "executionInfo": {
     "elapsed": 1038,
     "status": "ok",
     "timestamp": 1764456096452,
     "user": {
      "displayName": "Sonya Kukulina",
      "userId": "10766522173340573677"
     },
     "user_tz": -60
    },
    "id": "8a7d1f26-92bb-4557-b748-e6acf787e94c",
    "outputId": "f9bd6983-dd31-4141-9f74-926fc89f8fb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantum Reservoir Created:\n",
      "  Input size (PCA components): 32\n",
      "  Quantum output size: 330\n",
      "  Total features to classifier: 554\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"2261.25\" height=\"531.25\" viewBox=\"-29.5 0 1809.0 425.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L75,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M30,40 L39,40 L53,10 L44,10 L30,40 L39,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"47\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=px1</text>\n",
       "<path d=\"M25,75 L75,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M30,90 L39,90 L53,60 L44,60 L30,90 L39,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"47\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=px2</text>\n",
       "<path d=\"M25,125 L75,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M30,140 L39,140 L53,110 L44,110 L30,140 L39,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"47\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=px3</text>\n",
       "<path d=\"M25,175 L75,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M30,190 L39,190 L53,160 L44,160 L30,190 L39,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"47\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=px4</text>\n",
       "<path d=\"M25,225 L75,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M30,240 L39,240 L53,210 L44,210 L30,240 L39,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"47\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=px5</text>\n",
       "<path d=\"M25,275 L75,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M30,290 L39,290 L53,260 L44,260 L30,290 L39,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"47\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=px6</text>\n",
       "<path d=\"M25,325 L75,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M30,340 L39,340 L53,310 L44,310 L30,340 L39,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"47\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=px7</text>\n",
       "<path d=\"M25,375 L75,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M30,390 L39,390 L53,360 L44,360 L30,390 L39,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"47\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=px8</text>\n",
       "<path d=\"M75,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M80,40 L89,40 L103,10 L94,10 L80,40 L89,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"97\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=px9</text>\n",
       "<path d=\"M75,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M80,90 L89,90 L103,60 L94,60 L80,90 L89,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"97\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=px10</text>\n",
       "<path d=\"M75,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M80,140 L89,140 L103,110 L94,110 L80,140 L89,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"97\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=px11</text>\n",
       "<path d=\"M75,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M80,190 L89,190 L103,160 L94,160 L80,190 L89,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"97\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=px12</text>\n",
       "<path d=\"M75,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M80,240 L89,240 L103,210 L94,210 L80,240 L89,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"97\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=px13</text>\n",
       "<path d=\"M75,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M80,290 L89,290 L103,260 L94,260 L80,290 L89,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"97\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=px14</text>\n",
       "<path d=\"M75,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M80,340 L89,340 L103,310 L94,310 L80,340 L89,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"97\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=px15</text>\n",
       "<path d=\"M75,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M80,390 L89,390 L103,360 L94,360 L80,390 L89,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"97\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=px16</text>\n",
       "<path d=\"M125,25 L153,25 L172,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M178,44 L197,25 L225,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M125,75 L153,75 L172,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M178,56 L197,75 L225,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M150,43 L200,43 L200,57 L150,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"175\" y=\"85\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"175\" y=\"26\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<path d=\"M150,43 L200,43 L200,47 L150,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M193,50 L203,50 L203,60 L193,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"198\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125.0 L225,125.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M225,75 L253,75 L272,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M278,94 L297,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M225,125 L253,125 L272,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M278,106 L297,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M250,93 L300,93 L300,107 L250,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"275\" y=\"135\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"275\" y=\"76\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<path d=\"M250,93 L300,93 L300,97 L250,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M293,100 L303,100 L303,110 L293,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"298\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,175.0 L325,175.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"185\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225.0 L425,225.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M425,175 L453,175 L472,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M478,194 L497,175 L525,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M425,225 L453,225 L472,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M478,206 L497,225 L525,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M450,193 L500,193 L500,207 L450,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"475\" y=\"235\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"475\" y=\"176\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<path d=\"M450,193 L500,193 L500,197 L450,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M493,200 L503,200 L503,210 L493,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"498\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,275.0 L525,275.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M525,225 L553,225 L572,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M578,244 L597,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M525,275 L553,275 L572,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M578,256 L597,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M550,243 L600,243 L600,257 L550,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"575\" y=\"285\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"575\" y=\"226\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<path d=\"M550,243 L600,243 L600,247 L550,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M593,250 L603,250 L603,260 L593,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"598\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325.0 L625,325.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,294 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,325 L653,325 L672,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,306 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,293 L700,293 L700,307 L650,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"335\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"276\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<path d=\"M650,293 L700,293 L700,297 L650,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,300 L703,300 L703,310 L693,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,375.0 L725,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M725,325 L753,325 L772,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M778,344 L797,325 L825,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M725,375 L753,375 L772,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M778,356 L797,375 L825,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M750,343 L800,343 L800,357 L750,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"775\" y=\"385\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"775\" y=\"326\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<path d=\"M750,343 L800,343 L800,347 L750,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M793,350 L803,350 L803,360 L793,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"798\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M225,25.0 L825,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75.0 L825,75.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M425,125.0 L825,125.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M525,175.0 L825,175.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,225.0 L825,225.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M725,275.0 L825,275.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M825,25 L925,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M825,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M825,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M825,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M825,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M825,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M825,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M825,375 L925,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M827.5,2.5 L922.5,2.5 L922.5,397.5 L827.5,397.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"835\" y=\"16\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">CPLX</text>\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"85\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M925,125.0 L1025,125.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1025,75 L1053,75 L1072,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1078,94 L1097,75 L1125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1025,125 L1053,125 L1072,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1078,106 L1097,125 L1125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1050,93 L1100,93 L1100,107 L1050,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1075\" y=\"135\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1075\" y=\"76\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<path d=\"M1050,93 L1100,93 L1100,97 L1050,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1093,100 L1103,100 L1103,110 L1093,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1098\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M925,175.0 L1125,175.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1125,125 L1153,125 L1172,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1178,144 L1197,125 L1225,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1125,175 L1153,175 L1172,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1178,156 L1197,175 L1225,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1150,143 L1200,143 L1200,157 L1150,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1175\" y=\"185\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1175\" y=\"126\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<path d=\"M1150,143 L1200,143 L1200,147 L1150,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1193,150 L1203,150 L1203,160 L1193,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1198\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M925,225.0 L1225,225.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,175 L1253,175 L1272,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,194 L1297,175 L1325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,225 L1253,225 L1272,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,206 L1297,225 L1325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1250,193 L1300,193 L1300,207 L1250,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1275\" y=\"235\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1275\" y=\"176\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<path d=\"M1250,193 L1300,193 L1300,197 L1250,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1293,200 L1303,200 L1303,210 L1293,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1298\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M925,275.0 L1325,275.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1325,225 L1353,225 L1372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1378,244 L1397,225 L1425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1325,275 L1353,275 L1372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1378,256 L1397,275 L1425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1350,243 L1400,243 L1400,257 L1350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1375\" y=\"285\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<path d=\"M1350,243 L1400,243 L1400,247 L1350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1393,250 L1403,250 L1403,260 L1393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M925,325.0 L1425,325.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1425,275 L1453,275 L1472,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1478,294 L1497,275 L1525,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1425,325 L1453,325 L1472,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1478,306 L1497,325 L1525,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1450,293 L1500,293 L1500,307 L1450,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1475\" y=\"335\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1475\" y=\"276\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<path d=\"M1450,293 L1500,293 L1500,297 L1450,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1493,300 L1503,300 L1503,310 L1493,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1498\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M925,375.0 L1525,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1525,325 L1553,325 L1572,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,344 L1597,325 L1625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1525,375 L1553,375 L1572,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,356 L1597,375 L1625,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1550,343 L1600,343 L1600,357 L1550,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1575\" y=\"385\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1575\" y=\"326\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<path d=\"M1550,343 L1600,343 L1600,347 L1550,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1593,350 L1603,350 L1603,360 L1593,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1598\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=px17</text>\n",
       "<path d=\"M1125,75 L1175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1130,90 L1139,90 L1153,60 L1144,60 L1130,90 L1139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=px18</text>\n",
       "<path d=\"M1225,125 L1275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1230,140 L1239,140 L1253,110 L1244,110 L1230,140 L1239,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1247\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=px19</text>\n",
       "<path d=\"M1325,175 L1375,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,190 L1339,190 L1353,160 L1344,160 L1330,190 L1339,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=px20</text>\n",
       "<path d=\"M1425,225 L1475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1430,240 L1439,240 L1453,210 L1444,210 L1430,240 L1439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=px21</text>\n",
       "<path d=\"M1525,275 L1575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1530,290 L1539,290 L1553,260 L1544,260 L1530,290 L1539,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1547\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=px22</text>\n",
       "<path d=\"M1625,325 L1675,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,340 L1639,340 L1653,310 L1644,310 L1630,340 L1639,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=px23</text>\n",
       "<path d=\"M1625,375 L1675,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,390 L1639,390 L1653,360 L1644,360 L1630,390 L1639,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=px24</text>\n",
       "<path d=\"M1075,25 L1125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1080,40 L1089,40 L1103,10 L1094,10 L1080,40 L1089,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1097\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=px25</text>\n",
       "<path d=\"M1175,75 L1225,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,90 L1189,90 L1203,60 L1194,60 L1180,90 L1189,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=px26</text>\n",
       "<path d=\"M1275,125 L1325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1280,140 L1289,140 L1303,110 L1294,110 L1280,140 L1289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=px27</text>\n",
       "<path d=\"M1375,175 L1425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1380,190 L1389,190 L1403,160 L1394,160 L1380,190 L1389,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1397\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=px28</text>\n",
       "<path d=\"M1475,225 L1525,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,240 L1489,240 L1503,210 L1494,210 L1480,240 L1489,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=px29</text>\n",
       "<path d=\"M1575,275 L1625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1580,290 L1589,290 L1603,260 L1594,260 L1580,290 L1589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=px30</text>\n",
       "<path d=\"M1675,325 L1725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1680,340 L1689,340 L1703,310 L1694,310 L1680,340 L1689,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1697\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=px31</text>\n",
       "<path d=\"M1675,375 L1725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1680,390 L1689,390 L1703,360 L1694,360 L1680,390 L1689,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1697\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=px32</text>\n",
       "<path d=\"M1125,25.0 L1725,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,75.0 L1725,75.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1325,125.0 L1725,125.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1425,175.0 L1725,175.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1525,225.0 L1725,225.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1625,275.0 L1725,275.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1725,25.0 L1740,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1725,75.0 L1740,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1725,125.0 L1740,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1725,175.0 L1740,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1725,225.0 L1740,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1725,275.0 L1740,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1725,325.0 L1740,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1725,375.0 L1740,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1750\" y=\"28.0\" font-size=\"9\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1750\" y=\"78.0\" font-size=\"9\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1750\" y=\"128.0\" font-size=\"9\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1750\" y=\"178.0\" font-size=\"9\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1750\" y=\"228.0\" font-size=\"9\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1750\" y=\"278.0\" font-size=\"9\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1750\" y=\"328.0\" font-size=\"9\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1750\" y=\"378.0\" font-size=\"9\" text-anchor=\"end\">7</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"9\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"9\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"9\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"9\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"9\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"9\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"9\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"9\" text-anchor=\"start\">7</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x175afd4a230>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dim = X_train_flat.shape[1]\n",
    "\n",
    "# define corresponding linear model for comparison (not used here)\n",
    "# linear_model = LinearModelBaseline(X_train_flat.shape[1])\n",
    "\n",
    "# define model using pca features (not used here)\n",
    "# pca_model = LinearModelPCA(X_train_flat.shape[1], n_components)\n",
    "\n",
    "# define hybrid model\n",
    "hybrid_model = QuantumReservoir(X_train_flat.shape[1], n_components, n_modes=N_MODES, n_photons=N_PHOTONS)\n",
    "pcvl.pdisplay(hybrid_model.quantum_layer.circuit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dedd2f9",
   "metadata": {},
   "source": [
    "# 4) Testing and Training the Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43a8518c-3684-4d2e-a1d0-0ac906df81a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 118512,
     "status": "ok",
     "timestamp": 1764456215019,
     "user": {
      "displayName": "Sonya Kukulina",
      "userId": "10766522173340573677"
     },
     "user_tz": -60
    },
    "id": "43a8518c-3684-4d2e-a1d0-0ac906df81a1",
    "outputId": "c4f47c73-f160-4d2e-9e72-69c4f2875545"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], TRAIN LOSS -- Hybrid: 0.2190 \n",
      "TEST LOSS -- Hybrid: 0.0759\n",
      "Epoch [2/100], TRAIN LOSS -- Hybrid: 0.1675 \n",
      "TEST LOSS -- Hybrid: 0.0580\n",
      "Epoch [3/100], TRAIN LOSS -- Hybrid: 0.1289 \n",
      "TEST LOSS -- Hybrid: 0.0441\n",
      "Epoch [4/100], TRAIN LOSS -- Hybrid: 0.0964 \n",
      "TEST LOSS -- Hybrid: 0.0337\n",
      "Epoch [5/100], TRAIN LOSS -- Hybrid: 0.0741 \n",
      "TEST LOSS -- Hybrid: 0.0259\n",
      "Epoch [6/100], TRAIN LOSS -- Hybrid: 0.0564 \n",
      "TEST LOSS -- Hybrid: 0.0201\n",
      "Epoch [7/100], TRAIN LOSS -- Hybrid: 0.0433 \n",
      "TEST LOSS -- Hybrid: 0.0161\n",
      "Epoch [8/100], TRAIN LOSS -- Hybrid: 0.0348 \n",
      "TEST LOSS -- Hybrid: 0.0131\n",
      "Epoch [9/100], TRAIN LOSS -- Hybrid: 0.0280 \n",
      "TEST LOSS -- Hybrid: 0.0109\n",
      "Epoch [10/100], TRAIN LOSS -- Hybrid: 0.0237 \n",
      "TEST LOSS -- Hybrid: 0.0094\n",
      "Epoch [11/100], TRAIN LOSS -- Hybrid: 0.0201 \n",
      "TEST LOSS -- Hybrid: 0.0083\n",
      "Epoch [12/100], TRAIN LOSS -- Hybrid: 0.0178 \n",
      "TEST LOSS -- Hybrid: 0.0075\n",
      "Epoch [13/100], TRAIN LOSS -- Hybrid: 0.0158 \n",
      "TEST LOSS -- Hybrid: 0.0069\n",
      "Epoch [14/100], TRAIN LOSS -- Hybrid: 0.0142 \n",
      "TEST LOSS -- Hybrid: 0.0065\n",
      "Epoch [15/100], TRAIN LOSS -- Hybrid: 0.0136 \n",
      "TEST LOSS -- Hybrid: 0.0062\n",
      "Epoch [16/100], TRAIN LOSS -- Hybrid: 0.0126 \n",
      "TEST LOSS -- Hybrid: 0.0059\n",
      "Epoch [17/100], TRAIN LOSS -- Hybrid: 0.0120 \n",
      "TEST LOSS -- Hybrid: 0.0057\n",
      "Epoch [18/100], TRAIN LOSS -- Hybrid: 0.0116 \n",
      "TEST LOSS -- Hybrid: 0.0055\n",
      "Epoch [19/100], TRAIN LOSS -- Hybrid: 0.0113 \n",
      "TEST LOSS -- Hybrid: 0.0054\n",
      "Epoch [20/100], TRAIN LOSS -- Hybrid: 0.0110 \n",
      "TEST LOSS -- Hybrid: 0.0052\n",
      "Epoch [21/100], TRAIN LOSS -- Hybrid: 0.0105 \n",
      "TEST LOSS -- Hybrid: 0.0051\n",
      "Epoch [22/100], TRAIN LOSS -- Hybrid: 0.0104 \n",
      "TEST LOSS -- Hybrid: 0.0050\n",
      "Epoch [23/100], TRAIN LOSS -- Hybrid: 0.0099 \n",
      "TEST LOSS -- Hybrid: 0.0049\n",
      "Epoch [24/100], TRAIN LOSS -- Hybrid: 0.0095 \n",
      "TEST LOSS -- Hybrid: 0.0048\n",
      "Epoch [25/100], TRAIN LOSS -- Hybrid: 0.0095 \n",
      "TEST LOSS -- Hybrid: 0.0048\n",
      "Epoch [26/100], TRAIN LOSS -- Hybrid: 0.0094 \n",
      "TEST LOSS -- Hybrid: 0.0047\n",
      "Epoch [27/100], TRAIN LOSS -- Hybrid: 0.0092 \n",
      "TEST LOSS -- Hybrid: 0.0046\n",
      "Epoch [28/100], TRAIN LOSS -- Hybrid: 0.0091 \n",
      "TEST LOSS -- Hybrid: 0.0045\n",
      "Epoch [29/100], TRAIN LOSS -- Hybrid: 0.0088 \n",
      "TEST LOSS -- Hybrid: 0.0044\n",
      "Epoch [30/100], TRAIN LOSS -- Hybrid: 0.0085 \n",
      "TEST LOSS -- Hybrid: 0.0043\n",
      "Epoch [31/100], TRAIN LOSS -- Hybrid: 0.0083 \n",
      "TEST LOSS -- Hybrid: 0.0043\n",
      "Epoch [32/100], TRAIN LOSS -- Hybrid: 0.0083 \n",
      "TEST LOSS -- Hybrid: 0.0042\n",
      "Epoch [33/100], TRAIN LOSS -- Hybrid: 0.0078 \n",
      "TEST LOSS -- Hybrid: 0.0041\n",
      "Epoch [34/100], TRAIN LOSS -- Hybrid: 0.0079 \n",
      "TEST LOSS -- Hybrid: 0.0041\n",
      "Epoch [35/100], TRAIN LOSS -- Hybrid: 0.0078 \n",
      "TEST LOSS -- Hybrid: 0.0040\n",
      "Epoch [36/100], TRAIN LOSS -- Hybrid: 0.0074 \n",
      "TEST LOSS -- Hybrid: 0.0039\n",
      "Epoch [37/100], TRAIN LOSS -- Hybrid: 0.0073 \n",
      "TEST LOSS -- Hybrid: 0.0038\n",
      "Epoch [38/100], TRAIN LOSS -- Hybrid: 0.0072 \n",
      "TEST LOSS -- Hybrid: 0.0038\n",
      "Epoch [39/100], TRAIN LOSS -- Hybrid: 0.0071 \n",
      "TEST LOSS -- Hybrid: 0.0037\n",
      "Epoch [40/100], TRAIN LOSS -- Hybrid: 0.0069 \n",
      "TEST LOSS -- Hybrid: 0.0037\n",
      "Epoch [41/100], TRAIN LOSS -- Hybrid: 0.0067 \n",
      "TEST LOSS -- Hybrid: 0.0036\n",
      "Epoch [42/100], TRAIN LOSS -- Hybrid: 0.0065 \n",
      "TEST LOSS -- Hybrid: 0.0035\n",
      "Epoch [43/100], TRAIN LOSS -- Hybrid: 0.0065 \n",
      "TEST LOSS -- Hybrid: 0.0035\n",
      "Epoch [44/100], TRAIN LOSS -- Hybrid: 0.0062 \n",
      "TEST LOSS -- Hybrid: 0.0034\n",
      "Epoch [45/100], TRAIN LOSS -- Hybrid: 0.0061 \n",
      "TEST LOSS -- Hybrid: 0.0034\n",
      "Epoch [46/100], TRAIN LOSS -- Hybrid: 0.0060 \n",
      "TEST LOSS -- Hybrid: 0.0034\n",
      "Epoch [47/100], TRAIN LOSS -- Hybrid: 0.0058 \n",
      "TEST LOSS -- Hybrid: 0.0033\n",
      "Epoch [48/100], TRAIN LOSS -- Hybrid: 0.0057 \n",
      "TEST LOSS -- Hybrid: 0.0032\n",
      "Epoch [49/100], TRAIN LOSS -- Hybrid: 0.0055 \n",
      "TEST LOSS -- Hybrid: 0.0032\n",
      "Epoch [50/100], TRAIN LOSS -- Hybrid: 0.0055 \n",
      "TEST LOSS -- Hybrid: 0.0031\n",
      "Epoch [51/100], TRAIN LOSS -- Hybrid: 0.0054 \n",
      "TEST LOSS -- Hybrid: 0.0031\n",
      "Epoch [52/100], TRAIN LOSS -- Hybrid: 0.0053 \n",
      "TEST LOSS -- Hybrid: 0.0031\n",
      "Epoch [53/100], TRAIN LOSS -- Hybrid: 0.0051 \n",
      "TEST LOSS -- Hybrid: 0.0030\n",
      "Epoch [54/100], TRAIN LOSS -- Hybrid: 0.0051 \n",
      "TEST LOSS -- Hybrid: 0.0030\n",
      "Epoch [55/100], TRAIN LOSS -- Hybrid: 0.0050 \n",
      "TEST LOSS -- Hybrid: 0.0029\n",
      "Epoch [56/100], TRAIN LOSS -- Hybrid: 0.0049 \n",
      "TEST LOSS -- Hybrid: 0.0029\n",
      "Epoch [57/100], TRAIN LOSS -- Hybrid: 0.0048 \n",
      "TEST LOSS -- Hybrid: 0.0029\n",
      "Epoch [58/100], TRAIN LOSS -- Hybrid: 0.0047 \n",
      "TEST LOSS -- Hybrid: 0.0028\n",
      "Epoch [59/100], TRAIN LOSS -- Hybrid: 0.0046 \n",
      "TEST LOSS -- Hybrid: 0.0028\n",
      "Epoch [60/100], TRAIN LOSS -- Hybrid: 0.0045 \n",
      "TEST LOSS -- Hybrid: 0.0028\n",
      "Epoch [61/100], TRAIN LOSS -- Hybrid: 0.0044 \n",
      "TEST LOSS -- Hybrid: 0.0027\n",
      "Epoch [62/100], TRAIN LOSS -- Hybrid: 0.0043 \n",
      "TEST LOSS -- Hybrid: 0.0027\n",
      "Epoch [63/100], TRAIN LOSS -- Hybrid: 0.0042 \n",
      "TEST LOSS -- Hybrid: 0.0027\n",
      "Epoch [64/100], TRAIN LOSS -- Hybrid: 0.0041 \n",
      "TEST LOSS -- Hybrid: 0.0027\n",
      "Epoch [65/100], TRAIN LOSS -- Hybrid: 0.0041 \n",
      "TEST LOSS -- Hybrid: 0.0026\n",
      "Epoch [66/100], TRAIN LOSS -- Hybrid: 0.0040 \n",
      "TEST LOSS -- Hybrid: 0.0026\n",
      "Epoch [67/100], TRAIN LOSS -- Hybrid: 0.0039 \n",
      "TEST LOSS -- Hybrid: 0.0025\n",
      "Epoch [68/100], TRAIN LOSS -- Hybrid: 0.0038 \n",
      "TEST LOSS -- Hybrid: 0.0025\n",
      "Epoch [69/100], TRAIN LOSS -- Hybrid: 0.0037 \n",
      "TEST LOSS -- Hybrid: 0.0025\n",
      "Epoch [70/100], TRAIN LOSS -- Hybrid: 0.0037 \n",
      "TEST LOSS -- Hybrid: 0.0025\n",
      "Epoch [71/100], TRAIN LOSS -- Hybrid: 0.0037 \n",
      "TEST LOSS -- Hybrid: 0.0025\n",
      "Epoch [72/100], TRAIN LOSS -- Hybrid: 0.0036 \n",
      "TEST LOSS -- Hybrid: 0.0024\n",
      "Epoch [73/100], TRAIN LOSS -- Hybrid: 0.0037 \n",
      "TEST LOSS -- Hybrid: 0.0024\n",
      "Epoch [74/100], TRAIN LOSS -- Hybrid: 0.0034 \n",
      "TEST LOSS -- Hybrid: 0.0024\n",
      "Epoch [75/100], TRAIN LOSS -- Hybrid: 0.0035 \n",
      "TEST LOSS -- Hybrid: 0.0024\n",
      "Epoch [76/100], TRAIN LOSS -- Hybrid: 0.0034 \n",
      "TEST LOSS -- Hybrid: 0.0023\n",
      "Epoch [77/100], TRAIN LOSS -- Hybrid: 0.0034 \n",
      "TEST LOSS -- Hybrid: 0.0023\n",
      "Epoch [78/100], TRAIN LOSS -- Hybrid: 0.0033 \n",
      "TEST LOSS -- Hybrid: 0.0023\n",
      "Epoch [79/100], TRAIN LOSS -- Hybrid: 0.0032 \n",
      "TEST LOSS -- Hybrid: 0.0023\n",
      "Epoch [80/100], TRAIN LOSS -- Hybrid: 0.0032 \n",
      "TEST LOSS -- Hybrid: 0.0023\n",
      "Epoch [81/100], TRAIN LOSS -- Hybrid: 0.0032 \n",
      "TEST LOSS -- Hybrid: 0.0022\n",
      "Epoch [82/100], TRAIN LOSS -- Hybrid: 0.0030 \n",
      "TEST LOSS -- Hybrid: 0.0022\n",
      "Epoch [83/100], TRAIN LOSS -- Hybrid: 0.0031 \n",
      "TEST LOSS -- Hybrid: 0.0022\n",
      "Epoch [84/100], TRAIN LOSS -- Hybrid: 0.0031 \n",
      "TEST LOSS -- Hybrid: 0.0022\n",
      "Epoch [85/100], TRAIN LOSS -- Hybrid: 0.0030 \n",
      "TEST LOSS -- Hybrid: 0.0022\n",
      "Epoch [86/100], TRAIN LOSS -- Hybrid: 0.0029 \n",
      "TEST LOSS -- Hybrid: 0.0022\n",
      "Epoch [87/100], TRAIN LOSS -- Hybrid: 0.0029 \n",
      "TEST LOSS -- Hybrid: 0.0021\n",
      "Epoch [88/100], TRAIN LOSS -- Hybrid: 0.0029 \n",
      "TEST LOSS -- Hybrid: 0.0021\n",
      "Epoch [89/100], TRAIN LOSS -- Hybrid: 0.0028 \n",
      "TEST LOSS -- Hybrid: 0.0021\n",
      "Epoch [90/100], TRAIN LOSS -- Hybrid: 0.0028 \n",
      "TEST LOSS -- Hybrid: 0.0021\n",
      "Epoch [91/100], TRAIN LOSS -- Hybrid: 0.0027 \n",
      "TEST LOSS -- Hybrid: 0.0021\n",
      "Epoch [92/100], TRAIN LOSS -- Hybrid: 0.0027 \n",
      "TEST LOSS -- Hybrid: 0.0021\n",
      "Epoch [93/100], TRAIN LOSS -- Hybrid: 0.0027 \n",
      "TEST LOSS -- Hybrid: 0.0021\n",
      "Epoch [94/100], TRAIN LOSS -- Hybrid: 0.0027 \n",
      "TEST LOSS -- Hybrid: 0.0020\n",
      "Epoch [95/100], TRAIN LOSS -- Hybrid: 0.0026 \n",
      "TEST LOSS -- Hybrid: 0.0020\n",
      "Epoch [96/100], TRAIN LOSS -- Hybrid: 0.0027 \n",
      "TEST LOSS -- Hybrid: 0.0020\n",
      "Epoch [97/100], TRAIN LOSS -- Hybrid: 0.0025 \n",
      "TEST LOSS -- Hybrid: 0.0020\n",
      "Epoch [98/100], TRAIN LOSS -- Hybrid: 0.0026 \n",
      "TEST LOSS -- Hybrid: 0.0020\n",
      "Epoch [99/100], TRAIN LOSS -- Hybrid: 0.0026 \n",
      "TEST LOSS -- Hybrid: 0.0020\n",
      "Epoch [100/100], TRAIN LOSS -- Hybrid: 0.0025 \n",
      "TEST LOSS -- Hybrid: 0.0020\n"
     ]
    }
   ],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer_hybrid = torch.optim.Adam(hybrid_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# alternative optimizers (not used further):\n",
    "# optimizer_linear = torch.optim.Adam(linear_model.parameters(), lr=0.001)\n",
    "# optimizer_pca = torch.optim.Adam(pca_model.parameters(), lr=0.001)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "batch_size = BATCH_SIZE\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train_tensor, X_train_pca, torch.Tensor(y_train))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Dictionary for quality analysis\n",
    "history = {\n",
    "      'hybrid': {'loss': [], 'accuracy': []},\n",
    "      'pca': {'loss': [], 'accuracy': []},\n",
    "      'linear': {'loss': [], 'accuracy': []},\n",
    "      'epochs': []\n",
    "}\n",
    "\n",
    "# Main training loop\n",
    "num_epochs = EPOCHS\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss_hybrid = 0.0\n",
    "    running_loss_linear = 0.0\n",
    "    running_loss_pca = 0.0\n",
    "\n",
    "    hybrid_model.train()\n",
    "    # alternative models:\n",
    "    # linear_model.train()\n",
    "    # pca_model.train()\n",
    "\n",
    "    for i, (n_swaps, pca_features, labels) in enumerate(train_loader):\n",
    "        # Hybrid model - Forward and Backward pass\n",
    "        outputs = hybrid_model(n_swaps, pca_features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer_hybrid.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_hybrid.step()\n",
    "        running_loss_hybrid += loss.item()\n",
    "\n",
    "        # # Comparative linear model - Forward and Backward pass\n",
    "        # outputs = linear_model(images)\n",
    "        # loss = criterion(outputs, labels)\n",
    "        # optimizer_linear.zero_grad()\n",
    "        # loss.backward()\n",
    "        # optimizer_linear.step()\n",
    "        # running_loss_linear += loss.item()\n",
    "\n",
    "        # # Comparative pca model - Forward and Backward pass\n",
    "        # outputs = pca_model(images, pca_features)\n",
    "        # loss = criterion(outputs, labels)\n",
    "        # optimizer_pca.zero_grad()\n",
    "        # loss.backward()\n",
    "        # optimizer_pca.step()\n",
    "        # running_loss_pca += loss.item()\n",
    "\n",
    "    avg_loss_hybrid = running_loss_hybrid/len(train_loader)\n",
    "    # avg_loss_linear = running_loss_linear/len(train_loader)\n",
    "    # avg_loss_pca = running_loss_pca/len(train_loader)\n",
    "\n",
    "    history['hybrid']['loss'].append(avg_loss_hybrid)\n",
    "    # history['linear']['loss'].append(avg_loss_linear)\n",
    "    # history['pca']['loss'].append(avg_loss_pca)\n",
    "\n",
    "    history['epochs'].append(epoch + 1)\n",
    "\n",
    "    hybrid_model.eval()\n",
    "    # alternative models:\n",
    "    # linear_model.eval()\n",
    "    # pca_model.eval()\n",
    "\n",
    "    # Cast X_test to tensor if it isn't already\n",
    "    X_test_tensor = torch.FloatTensor(X_test)\n",
    "    y_test_tensor = torch.FloatTensor(y_test)\n",
    "\n",
    "    # Model Testing\n",
    "    with torch.no_grad():\n",
    "        # Hybrid\n",
    "        outputs = hybrid_model(X_test_tensor, X_test_pca)\n",
    "        hybrid_test_loss = criterion(outputs, y_test_tensor).item()\n",
    "\n",
    "        # # Linear\n",
    "        # outputs = linear_model(X_test_tensor)\n",
    "        # linear_test_loss = criterion(outputs, y_test_tensor).item()\n",
    "\n",
    "        # # PCA\n",
    "        # outputs = pca_model(X_test_tensor, X_test_pca)\n",
    "        # pca_test_loss = criterion(outputs, y_test_tensor).item()\n",
    "\n",
    "    # Append losses\n",
    "    history['hybrid']['accuracy'].append(hybrid_test_loss)\n",
    "    \n",
    "    # history['linear']['accuracy'].append(linear_test_loss)\n",
    "    # history['pca']['accuracy'].append(pca_test_loss)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "          f'TRAIN LOSS -- Hybrid: {avg_loss_hybrid:.4f} \\n'\n",
    "          f'TEST LOSS -- Hybrid: {hybrid_test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bddf46",
   "metadata": {},
   "source": [
    "# 5) Model Performance Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f71bafbd-8a43-4f28-b831-48f140088ca9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1764456215042,
     "user": {
      "displayName": "Sonya Kukulina",
      "userId": "10766522173340573677"
     },
     "user_tz": -60
    },
    "id": "f71bafbd-8a43-4f28-b831-48f140088ca9",
    "outputId": "22db8481-8a61-414b-e4fe-f76c0e7cc849"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== HYBRID MODEL PERFORMANCE =====\n",
      "MSE  : 0.001975\n",
      "RMSE : 0.044443\n",
      "R²   : 0.826740\n"
     ]
    }
   ],
   "source": [
    "# Calculate statistical model quality parameters\n",
    "mse = mean_squared_error(y_test_tensor, outputs)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test_tensor, outputs)\n",
    "\n",
    "print(\"\\n===== HYBRID MODEL PERFORMANCE =====\")\n",
    "print(f\"MSE  : {mse:.6f}\")\n",
    "print(f\"RMSE : {rmse:.6f}\")\n",
    "print(f\"R²   : {r2:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432b426c",
   "metadata": {},
   "source": [
    "# 6) Data Prediction and Completion using the trained hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148523d3-1c1f-4b5c-a9e2-448f5c7c4397",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "executionInfo": {
     "elapsed": 154,
     "status": "ok",
     "timestamp": 1764456215198,
     "user": {
      "displayName": "Sonya Kukulina",
      "userId": "10766522173340573677"
     },
     "user_tz": -60
    },
    "id": "148523d3-1c1f-4b5c-a9e2-448f5c7c4397",
    "outputId": "622aaf06-57f6-4ac7-a62b-e4ef0291e891"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading template from price.xlsx...\n",
      "Found 224 feature columns to predict.\n",
      "Generating predictions for 8 steps...\n",
      "Predictions completed and saved to filled_predictions.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Tenor : 1; Maturity : 0.0833333333333333</th>\n",
       "      <th>Tenor : 2; Maturity : 0.0833333333333333</th>\n",
       "      <th>Tenor : 3; Maturity : 0.0833333333333333</th>\n",
       "      <th>Tenor : 4; Maturity : 0.0833333333333333</th>\n",
       "      <th>Tenor : 5; Maturity : 0.0833333333333333</th>\n",
       "      <th>Tenor : 6; Maturity : 0.0833333333333333</th>\n",
       "      <th>Tenor : 7; Maturity : 0.0833333333333333</th>\n",
       "      <th>Tenor : 8; Maturity : 0.0833333333333333</th>\n",
       "      <th>Tenor : 9; Maturity : 0.0833333333333333</th>\n",
       "      <th>...</th>\n",
       "      <th>Tenor : 6; Maturity : 30</th>\n",
       "      <th>Tenor : 7; Maturity : 30</th>\n",
       "      <th>Tenor : 8; Maturity : 30</th>\n",
       "      <th>Tenor : 9; Maturity : 30</th>\n",
       "      <th>Tenor : 10; Maturity : 30</th>\n",
       "      <th>Tenor : 15; Maturity : 30</th>\n",
       "      <th>Tenor : 20; Maturity : 30</th>\n",
       "      <th>Tenor : 25; Maturity : 30</th>\n",
       "      <th>Tenor : 30; Maturity : 30</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Future prediction</td>\n",
       "      <td>0.026504</td>\n",
       "      <td>0.034805</td>\n",
       "      <td>0.035573</td>\n",
       "      <td>0.037412</td>\n",
       "      <td>0.036505</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.035185</td>\n",
       "      <td>0.036594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325256</td>\n",
       "      <td>0.341107</td>\n",
       "      <td>0.334355</td>\n",
       "      <td>0.337350</td>\n",
       "      <td>0.330498</td>\n",
       "      <td>0.352365</td>\n",
       "      <td>0.364548</td>\n",
       "      <td>0.345545</td>\n",
       "      <td>0.336574</td>\n",
       "      <td>2051-12-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Future prediction</td>\n",
       "      <td>0.027271</td>\n",
       "      <td>0.034894</td>\n",
       "      <td>0.035819</td>\n",
       "      <td>0.037822</td>\n",
       "      <td>0.036703</td>\n",
       "      <td>0.036445</td>\n",
       "      <td>0.035937</td>\n",
       "      <td>0.035226</td>\n",
       "      <td>0.036692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328082</td>\n",
       "      <td>0.341116</td>\n",
       "      <td>0.334023</td>\n",
       "      <td>0.336082</td>\n",
       "      <td>0.332215</td>\n",
       "      <td>0.353194</td>\n",
       "      <td>0.365218</td>\n",
       "      <td>0.346290</td>\n",
       "      <td>0.334920</td>\n",
       "      <td>2051-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Future prediction</td>\n",
       "      <td>0.027319</td>\n",
       "      <td>0.035170</td>\n",
       "      <td>0.036249</td>\n",
       "      <td>0.037991</td>\n",
       "      <td>0.036808</td>\n",
       "      <td>0.036625</td>\n",
       "      <td>0.036187</td>\n",
       "      <td>0.035774</td>\n",
       "      <td>0.036890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328212</td>\n",
       "      <td>0.340768</td>\n",
       "      <td>0.333668</td>\n",
       "      <td>0.335928</td>\n",
       "      <td>0.332033</td>\n",
       "      <td>0.352763</td>\n",
       "      <td>0.364454</td>\n",
       "      <td>0.345547</td>\n",
       "      <td>0.334448</td>\n",
       "      <td>2051-12-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Future prediction</td>\n",
       "      <td>0.027398</td>\n",
       "      <td>0.035305</td>\n",
       "      <td>0.036442</td>\n",
       "      <td>0.038166</td>\n",
       "      <td>0.036954</td>\n",
       "      <td>0.036960</td>\n",
       "      <td>0.036442</td>\n",
       "      <td>0.036058</td>\n",
       "      <td>0.037071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328272</td>\n",
       "      <td>0.340561</td>\n",
       "      <td>0.333473</td>\n",
       "      <td>0.335442</td>\n",
       "      <td>0.331632</td>\n",
       "      <td>0.352776</td>\n",
       "      <td>0.364207</td>\n",
       "      <td>0.345160</td>\n",
       "      <td>0.334157</td>\n",
       "      <td>2051-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Future prediction</td>\n",
       "      <td>0.027403</td>\n",
       "      <td>0.035393</td>\n",
       "      <td>0.036611</td>\n",
       "      <td>0.038352</td>\n",
       "      <td>0.037111</td>\n",
       "      <td>0.037173</td>\n",
       "      <td>0.036642</td>\n",
       "      <td>0.036321</td>\n",
       "      <td>0.037241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328487</td>\n",
       "      <td>0.340268</td>\n",
       "      <td>0.333107</td>\n",
       "      <td>0.335282</td>\n",
       "      <td>0.331617</td>\n",
       "      <td>0.352536</td>\n",
       "      <td>0.363952</td>\n",
       "      <td>0.344893</td>\n",
       "      <td>0.333942</td>\n",
       "      <td>2051-12-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Type  Tenor : 1; Maturity : 0.0833333333333333  \\\n",
       "0  Future prediction                                  0.026504   \n",
       "1  Future prediction                                  0.027271   \n",
       "2  Future prediction                                  0.027319   \n",
       "3  Future prediction                                  0.027398   \n",
       "4  Future prediction                                  0.027403   \n",
       "\n",
       "   Tenor : 2; Maturity : 0.0833333333333333  \\\n",
       "0                                  0.034805   \n",
       "1                                  0.034894   \n",
       "2                                  0.035170   \n",
       "3                                  0.035305   \n",
       "4                                  0.035393   \n",
       "\n",
       "   Tenor : 3; Maturity : 0.0833333333333333  \\\n",
       "0                                  0.035573   \n",
       "1                                  0.035819   \n",
       "2                                  0.036249   \n",
       "3                                  0.036442   \n",
       "4                                  0.036611   \n",
       "\n",
       "   Tenor : 4; Maturity : 0.0833333333333333  \\\n",
       "0                                  0.037412   \n",
       "1                                  0.037822   \n",
       "2                                  0.037991   \n",
       "3                                  0.038166   \n",
       "4                                  0.038352   \n",
       "\n",
       "   Tenor : 5; Maturity : 0.0833333333333333  \\\n",
       "0                                  0.036505   \n",
       "1                                  0.036703   \n",
       "2                                  0.036808   \n",
       "3                                  0.036954   \n",
       "4                                  0.037111   \n",
       "\n",
       "   Tenor : 6; Maturity : 0.0833333333333333  \\\n",
       "0                                  0.036700   \n",
       "1                                  0.036445   \n",
       "2                                  0.036625   \n",
       "3                                  0.036960   \n",
       "4                                  0.037173   \n",
       "\n",
       "   Tenor : 7; Maturity : 0.0833333333333333  \\\n",
       "0                                  0.035294   \n",
       "1                                  0.035937   \n",
       "2                                  0.036187   \n",
       "3                                  0.036442   \n",
       "4                                  0.036642   \n",
       "\n",
       "   Tenor : 8; Maturity : 0.0833333333333333  \\\n",
       "0                                  0.035185   \n",
       "1                                  0.035226   \n",
       "2                                  0.035774   \n",
       "3                                  0.036058   \n",
       "4                                  0.036321   \n",
       "\n",
       "   Tenor : 9; Maturity : 0.0833333333333333  ...  Tenor : 6; Maturity : 30  \\\n",
       "0                                  0.036594  ...                  0.325256   \n",
       "1                                  0.036692  ...                  0.328082   \n",
       "2                                  0.036890  ...                  0.328212   \n",
       "3                                  0.037071  ...                  0.328272   \n",
       "4                                  0.037241  ...                  0.328487   \n",
       "\n",
       "   Tenor : 7; Maturity : 30  Tenor : 8; Maturity : 30  \\\n",
       "0                  0.341107                  0.334355   \n",
       "1                  0.341116                  0.334023   \n",
       "2                  0.340768                  0.333668   \n",
       "3                  0.340561                  0.333473   \n",
       "4                  0.340268                  0.333107   \n",
       "\n",
       "   Tenor : 9; Maturity : 30  Tenor : 10; Maturity : 30  \\\n",
       "0                  0.337350                   0.330498   \n",
       "1                  0.336082                   0.332215   \n",
       "2                  0.335928                   0.332033   \n",
       "3                  0.335442                   0.331632   \n",
       "4                  0.335282                   0.331617   \n",
       "\n",
       "   Tenor : 15; Maturity : 30  Tenor : 20; Maturity : 30  \\\n",
       "0                   0.352365                   0.364548   \n",
       "1                   0.353194                   0.365218   \n",
       "2                   0.352763                   0.364454   \n",
       "3                   0.352776                   0.364207   \n",
       "4                   0.352536                   0.363952   \n",
       "\n",
       "   Tenor : 25; Maturity : 30  Tenor : 30; Maturity : 30       Date  \n",
       "0                   0.345545                   0.336574 2051-12-24  \n",
       "1                   0.346290                   0.334920 2051-12-26  \n",
       "2                   0.345547                   0.334448 2051-12-27  \n",
       "3                   0.345160                   0.334157 2051-12-29  \n",
       "4                   0.344893                   0.333942 2051-12-30  \n",
       "\n",
       "[5 rows x 226 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "PREDICT_FILE = \"test_template.xlsx.xlsx\"             # file with missing prediction values\n",
    "OUTPUT_FILE = \"filled_predictions.csv\"  # output PATH\n",
    "\n",
    "print(f\"Loading template from {PREDICT_FILE}...\")\n",
    "\n",
    "# CSV parsing, or fallback to Excel \n",
    "try:\n",
    "    df_pred = pd.read_csv(PREDICT_FILE)\n",
    "except:\n",
    "    df_pred = pd.read_excel(PREDICT_FILE.replace(\".csv\", \"\"))\n",
    "\n",
    "# Identification of feature columns to be predicted (excluding metadata columns)\n",
    "metadata_cols = ['Date', 'Type', 'Unnamed: 0']\n",
    "feature_cols = [c for c in df_pred.columns if c not in metadata_cols]\n",
    "\n",
    "print(f\"Found {len(feature_cols)} feature columns to predict.\")\n",
    "\n",
    "# Starting State preparation (last state from the training data to be used for first future step prediction)\n",
    "last_state_scaled = y_all[-1]\n",
    "\n",
    "# Recursive Prediction Loop\n",
    "print(f\"Generating predictions for {len(df_pred)} steps...\")\n",
    "predictions_scaled = []\n",
    "current_input = last_state_scaled.reshape(1, -1) # Shape (1, n_features)\n",
    "\n",
    "hybrid_model.eval() # Set model to evaluation mode\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(df_pred)):\n",
    "        # Raw scaled features\n",
    "        X_tensor = torch.FloatTensor(current_input)\n",
    "\n",
    "        # Scaled PCA features\n",
    "        X_pca_tensor = torch.FloatTensor(pca.transform(current_input))\n",
    "\n",
    "        # Predict next state (scaled)\n",
    "        y_next_scaled = hybrid_model(X_tensor, X_pca_tensor)\n",
    "\n",
    "        # Convert to numpy\n",
    "        y_next_np = y_next_scaled.numpy()\n",
    "\n",
    "        # Store prediction\n",
    "        predictions_scaled.append(y_next_np.flatten())\n",
    "\n",
    "        # Update current_input for the next step (feeding prediction back as input)\n",
    "        current_input = y_next_np\n",
    "\n",
    "predictions_scaled = np.array(predictions_scaled)\n",
    "\n",
    "# Inverse scale to get actual prices/values\n",
    "predictions_original = scaler.inverse_transform(predictions_scaled)\n",
    "df_pred.loc[:, feature_cols] = predictions_original\n",
    "\n",
    "# Save to output file\n",
    "df_pred.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"Predictions completed and saved to {OUTPUT_FILE}\")\n",
    "\n",
    "# Display first few rows\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4079b320",
   "metadata": {},
   "source": [
    "# 7) Train and Test convergence results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "uP7C9-IKk4Cl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "executionInfo": {
     "elapsed": 358,
     "status": "ok",
     "timestamp": 1764456215576,
     "user": {
      "displayName": "Sonya Kukulina",
      "userId": "10766522173340573677"
     },
     "user_tz": -60
    },
    "id": "uP7C9-IKk4Cl",
    "outputId": "3e1188a6-d6ba-4186-a020-4420c871722f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training curve saved as 'training_curve.png'\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAHWCAYAAACbsXOkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAaW5JREFUeJzt3Qd8FHX+//HPJptCKiShhY6A9CJNFMspTeyign/vRPTkZ8F6nu0UsZxdzt77WUAsnAURRLCBoICCUkSkSQuhpdfd/+Pz3Z1lE5KQhGx/PR+PcXdnZ3cms+My7/1+v5+xOZ1OpwAAAAAADkvU4b0cAAAAAEC4AgAAAIAGQssVAAAAADQAwhUAAAAANADCFQAAAAA0AMIVAAAAADQAwhUAAAAANADCFQAAAAA0AMIVAAAAADQAwhUAICS99tprYrPZZOPGjXV+7ZQpU8xrg0H79u3l4osvrtdrTzzxRDMBAIID4QpARPv111/lr3/9q7Rq1Uri4uIkMzPTPF61apUEE90eDQT1CRK+pif3GlQ6d+5c5fNz5841z+v03nvvSShYsGCBZ5sPNUUqDYXe+6FZs2Zy3HHHyYcffhjoTQOAgLEHbtUAEFgffPCBXHDBBZKWliaXXnqpdOjQwYSXl19+2YSA6dOny5lnnhk04equu+4yQUZPaoNNfHy8/P7777JkyRIZNGhQhefeeust83xRUZGEim7dusl///vfCvNuvfVWSUpKkn/9618Nuq61a9dKVFT9fuucM2eOBFLfvn3lH//4h7m/bds2ef755+Wcc86RZ599Vi6//PKAbhsABALhCkBEWr9+vfztb3+Tjh07ytdffy1Nmzb1PHfttdeaX+C1BWvFihUmdKFmRxxxhJSVlck777xTIVxpoNKWjFNPPVXef//9kNmNzZs3N5+/twceeEAyMjIOmu/N4XBISUmJCZO1pS2m9RUbGyuBpC2+3vvjoosukk6dOsl//vOfasOVHie6n/yx7fX5PADgcNAtEEBEevjhh6WgoEBeeOGFCsFK6Qm0/gKfl5dnlrPouJiqWo2qGr/z6quvykknnWS6SunJc/fu3c2v+ZXp+5122mny7bffmlCiJ4Ea+N54440KY4vOO+88c/8vf/mLpxuWdl1Tel+34VBjeawxSrqua665xvzdjRs3lv/7v/8zJ6D79u0zJ8dNmjQx00033SROp7PW+1RbAbW1T09oLR9//LHZz+eff36Vr1m+fLmccsopkpKSYlqFTj75ZPn++++r7L6p+7NRo0bSunVruffeeyusx9tnn31mwnFiYqIkJyebYKev9wXdn5MmTTKtcz169DCf9ezZs81zjzzyiBxzzDGSnp5utrt///5Vdous7nP67rvv5IYbbjCfk/4tZ599tuzatavGMVdWd8Z3331X/v3vf5t9pceU7ldtWazs6aefNsebbp8ef998881hjeNq0aKFafXbsGGDeawtwbo9ui8ee+wxE8J1H1ndbr/88kvPZ6XHorYUr169+qD31b9rwIAB5m/R99D/P6v6/66mz2Pr1q1yySWXmOCs8/X5V1555aB1Pfnkk+a5hIQE8/+Brvftt9/2PJ+bmyvXXXed+dz0ffT/8eHDh8uyZcvqtc8AhBdargBEJD3p15MjPbGryvHHH2+e1+WeeeaZOr+/Bik9QTvjjDPEbreb97nyyitNILjqqqsqLKsnveeee67pmjh+/Hhzwqcn23oyru+h26Jh6IknnpDbbrvNnLwq67aurr76anMSrN0MNchowNQT24ULF0rbtm3lvvvuk1mzZplg2bNnTxO4auP//b//Z0549URYg5DSk1I9sdcT0Mo08Oj+12ClQS4mJsacNOuJ/VdffSWDBw82y+3YscOESm3xuOWWW8yJuG6zBoLKtCuf7sORI0fKgw8+aIKdfhZDhw41Qc4XXSo1IGiY0ZN6DebWOh5//HHz+V944YUmvE6bNs2E5E8++cQEvtp8Tnpyf+edd5qQouFE16EB9lC0lU27Gt54442yf/9+eeihh8x2LF682LOM7hd9P/0Mrr/+erOOs846y6xTQ1l9lJaWypYtW0ygrPxjg7ZiTpw40QQS7Yr7xRdfmGCt4U6Pm8LCQhNsjj32WBNUrP2on9uoUaOkZcuW5pgtLy+Xu++++6AfRWr6PHbu3ClHH320J3zpazWE6/9zOTk5JiypF1980fy/pv8/agu2brO2Xut+0+NbaYuchmR9H/3RZPfu3eYHCw2FRx11VL32G4Aw4gSACLNv3z5tjnGeeeaZNS53xhlnmOVycnLM4/HjxzvbtWt30HJ33nmnWc5bQUHBQcuNHDnS2bFjxwrz9P30tV9//bVnXlZWljMuLs75j3/8wzNvxowZZrn58+cf9L46X7ehMn1v3WbLq6++apbV7XA4HJ75Q4YMcdpsNufll1/umVdWVuZs3bq184QTTnAeii7To0cPc3/AgAHOSy+91Nzfu3evMzY21vn666+b7dZ1699hOeuss8zz69ev98zbtm2bMzk52Xn88cd75l133XXmtYsXL66wj1JTU838DRs2mHm5ubnOxo0bOy+77LIK27djxw6zrPf8qj6zQ9G/sfL+0PeIiopy/vrrrwctX/kYKCkpcfbs2dN50kkn1epzGjZsWIXP6frrr3dGR0eb49ei2+O9TdZ+7tatm7O4uNgz//HHHzfzV65caR7rc+np6c6BAwc6S0tLPcu99tprZrnafO663SNGjHDu2rXLTD///LNz3Lhx5vVXX321WUY/G32ckpJiPjNvffv2dTZr1sy5e/duzzx9D92fF110kWfe6aef7kxISHBu3brVM2/dunVOu91+0GdY3eehx2TLli2d2dnZFebr9uqxYX1W+p1gHcvV0eWvuuqqQ+4fAJGJboEAIo5261HaZawm1vPW8nXh3aqiLQfZ2dlywgknyB9//GEee9Nfv71b0PRX9SOPPNIs6wv6a713dyptIdLzUp1viY6ONt2h6roN+uu+FgrRlhr9dV/fR7uzVaatD1qMQVtKtOXCoq0T+h7aEqAtCkpb0bTVwXssl+4jbYmpXJVQuzZq90Td39ak26B/4/z588UX9HPVz7CmY2Dv3r3mc9fPubbdx7SVx/tz0tfqftu0adMhXzthwoQKY5qs48v6PH/88UfT4nLZZZeZllWL7lNtuaot/Qz1s9CpT58+MmPGDDOWUVsNvY0ZM6ZCS9P27dvlp59+Mi202opl6d27t+lip5+50r9XW7j0ONFKnhYd16WtXrX5PPTY1vF+p59+urnvfWxoC6d+LtZnoi24f/75p/zwww/V/s26jLZkaQEPAKiMboEAIk5tQ5M+rye32rWornS8jHbnWrRokema5k1P5lJTUz2PtSteZXqCqyfkvlB5fda2tGnT5qD5dd2GcePGma5o2uVKx73oeLKqQqyOHdL9oiGyMu3uqN0ntXuZdovUMGF1EfRW+bXr1q0zt1aXxMq0+6EvVFfwRLv/6dgwDRHFxcWe+bUt3175c7JCT20+k0O91gpoGlK8adCqS9dJ/Vz0b9S/Scco6Wen4eNQ+8haf3Wf/+effy75+fkmYGt3wcrbWdW2V7cuPdY0dGtXUp2qkpWVZW5vvvlmE+Y0yOv7jxgxwoR97apo0S6W2vVU/3/RrrujR482XWe9fyQAELkIVwAijoYG/RVcx1LURJ/XsSdWC0B1J8X663rlSoQ6zqhr164ydepUcxKm76G/xmsVtcqFGLRlpSp1KSZRm+061Pqqml/XbdCWJx0z9eijj5qA6c8KgdZ+1XFXOqasMu8WmoZU1dgvLQyh4610vJyO2dP9omPKdOyRd3GEmhzOceGrY6oy/eFh2LBh9dpHvlJ5XdZxoVUNNRRVRVvMrGCnpfE1GGshDD1+9fObPHmyGe+ltDiLdT0vbbnTsYnaUqctttW1pgGIHIQrABFJuwhp8QTtfqbFDqo6OdYB/lqtzfvXf/0FvLLK3bS0eIW2VHz00UcVWhAOp1taTa0dVW2XdsvTrleBoL/0//3vfzctGPqrflW0i5i2dOiJbGVr1qwxxRislrR27dp5WqW8VX6tVpFTWjyjNif8vqQn5VrZTltgvEuta7gKBrpPrWIqWizEokVD9Li3woav11/d56+hTQuX6D60rqFWWVXzqjvWtPVUf2yozXGh6x07dqyZ9P8jvW6XVl7U65xZJd01LGuBGp201UsLWegyhCsAjLkCEJG065qe3GsZch174m3Pnj2mIph2I9OKYN4n79qlz7vFSwOM/oJdVauBdyuBvu5wTqz1hE9VFe50u/RaXd60+1N1LVe+ppXWtEuk/uJf3bWMdB9pl6v//e9/5mTeolXdtGVHA6/VjU8DmlY11AsUe3f10m6H3nT8jL5Gqx1q1brKKpcx9yX9+zQQe38G+nfOnDlTgoGOp9OKflodTwOVRfepr7qjetNwohcgfv311ysc07/88otpDbJCue5HDUS637zHOGmw0q6ntaHvoWO+NPDq+9d0XFT+LtDjV8dv6f/Lekzp51l5zKSGeW0J9+76CSBy0XIFICLpeAq9lpQWP+jVq5cp5qBjNfQE+OWXXzYnmFo623v8ho4n0jEZWqBByzVbZb67dOlSoUiBhgY9KdPWMQ1ver0sPYnVk7D6tibpiaieJGr3Iz2509YQ6zpa2kqkYVBPILUYwM8//2xaTOozVqyhul1Wdd2tynSsjhah0CClLQDabU9bE/UkVce1WLRMu3b103LcWh7bKsWurR/eQVeDlX4eWlBBWxL089JWi82bN8unn35qxs089dRT4g9aal27hOo2a0uetm7oNaX0uDtUd1R/0ONTPyMt967HkXZ102Nfr7GlYb2248IOh3an05aeIUOGmP//rFLslY8fva+BSz+/K664wgQc/Rz1MgE6nq02tDS9thzrGDEt4qGBSX9E0f9vdYyV3rf+39UupbouvR6WllfXdennqa1fGgS1q7D+gKAFPPTabPp6LYChXWEBgHAFIGJpGNGTq/vvv19eeuklcwKs4zO068/SpUsPqgCnv/RrK5V2FdQTfg1e+lrtsuYdrnSQvlbKu/32200LmZ6s6UmhnujrRUzrQ9/jueeeM+vTE1E9wdSTRQ1XerKoF23VUKjjRHQ8iIYWHfcVzLRYhXa/1O5W+nfpvteT3zfffLNCAQtt5dC/VYOAniTr56BhUlsLvCscKg0yOl+X05N3DWqtWrUy+0Qr6PmLBhb9PHQ79BpKeqxoMNYAEwzhSmmrrLbIaCjQ41TDgnZl1R8OrO5vvqQtUnq8aiunjmnSMWla6U/3k/ePGlo0QlupdBvvuOMO011Ur3OlwUe7ENaGBiVt+dTX6dgobVXV40iPQe/KhvpjiLbeaTDWH0U0SOn+0P+XlbZ26w8BGvb0ffSY1cCs76f/jwOATeuxsxsAwEVbs7Q8tA5+1/tAJNGwoD8C6DgjbW0NZlqeXS9EXdV4PAAIFMZcAYAXLamsrSjaDe22225j3yBsFRUVHVQ9UH9Q0C5yWvExmGiXQW8aqLT6ZrBtJwDQcgUAQARasGCBXH/99XLeeeeZLnLatVW7Mmo5cu0WW10xkkDQrqHaoqzXktLqnDq2Trt8Ll++XDp37hzozQMAD8ZcAQAQgfRiwTp+6YknnjCtVWlpaablVseJBVOwUloY5J133pEdO3aYYi5aBEOrQhKsAAQbWq4AAAAAoAEw5goAAAAAGgDhCgAAAAAaAGOuqilFq1eC1wsG+uNCigAAAACCk1ZWzc3NNddRjIqquW2KcFUFDVY6yBcAAAAA1JYtW8zFxWtCuKqCtlhZOzAlJUV8rbS01FztfcSIEeYK9QDHDfjOQbDh3ypw3CBSv3NycnJMw4uVEWpCuKqC1RVQg5W/wlVCQoJZV6APHoQOjhtw7IDvHAQ7/q1COB07tRkuREELAAAAAGgAhCsAAAAAaACEKwAAAABoAIy5AgAAAOpRnrusrEzKy8vZdz4ac2W326WoqMjn+zg6OtqsqyEuwUS4AgAAAOqgpKREtm/fLgUFBew3H4bXFi1amOrd/rjurBbPaNmypcTGxh7W+xCuAAAAgFpyOByyYcMG09qhF5XVk3F/nPxH4n7Oy8uTpKSkQ16493BDnIblXbt2mc+1c+fOh7U+whUAAABQS3oirif+et0jbe2AbzgcDrOv4+PjfRquVKNGjUy5902bNnnWWV8UtAAAAADqehLt4xN+hObnyVEBAAAAAA2AcAUAAAAADYBwBQAAAKDO2rdvL4899hh7zgvhCgAAAAhjWs2wpmnKlCn1et8ffvhBJk6ceFjbduKJJ8p1110n4YJqgQAAAEAY02tyWaZPny6TJ0+WtWvXeuZpuXPv0uR60V69qO6hNG3a1AdbG9pouQpy17yzXE56ZIEs27w30JsCAACAKmggKSgp8/uk660NvRivNaWmpprWKuvxmjVrJDk5WT777DPp37+/xMXFybfffivr16+XM888U5o3b27C18CBA+WLL76osVugzWaTl156Sc4++2xTpl6vGfXRRx8d1jHz/vvvS48ePcx26foeffTRCs8/88wzZj1aPl239dxzz/U8995770mvXr1MqfX09HQZNmyY5Ofniy/RchXktu4rlD+y8yUrpyjQmwIAAIAqFJaWS/fJn/t936y6e6QkxDbM6fwtt9wijzzyiHTs2FGaNGkiW7ZskdGjR8u///1vE2zeeOMNOf30002LV9u2bat9n7vuukseeughefjhh+XJJ5+UCy+80Fw/Ki0trc7b9NNPP8m4ceNMt8WxY8fKwoUL5corrzRB6eKLL5Yff/xRrrnmGvnvf/8rxxxzjOzZs0e++eYbT2vdBRdcYLZFw15ubq55rraBtL4IV0EuPTHW3GbnlQR6UwAAABCm7r77bhk+fLjnsYahPn36eB7fc8898uGHH5qWqEmTJlX7PhdffLEJNeq+++6TJ554QpYsWSKjRo2q8zY9/fTTctJJJ8kdd9xhHnfp0kVWrVplgpuuZ/PmzZKYmCinnXaaaX1r166d9OvXzxOuysrK5JxzzjHzlbZi+RrhKsilJ8WZ292EKwAAgKDUKCbatCIFYr0NZcCAARUe5+XlmRajTz/91BNUCgsLTaCpSe/evT33NfikpKRIVlZWvbbpt99+M61O3o499ljTFVHHhWkY1OCkrW0a3nSyuiRqMDz55JNNoBo5cqSMGDHCdBnUVjlfYsxVkMtIcrVc7c4vDvSmAAAAoAo61ki75/l70vU2FA1C3m688UbTUqWtT9qdTrvoaVApKam5N1VMTMxB+8bhcIgvaGvVsmXL5J133pGWLVuaQh0aqvbt2yfR0dEyd+5cM5ase/fupovikUceKRs2bBBfIlyFSLdAWq4AAADgL999953peqctQRqqtPjFxo0b/foBdOnSxWxH5e3S+RqelFY11EIVOrZqxYoVZhu//PJLT7DTli4dB7Z8+XKJjY01gdGX6BYYIt0Cs/NouQIAAIB/aAW+Dz74wBSx0JCi45581QK1a9cu0zLmTSv/6dguHXOl4720oMWiRYvkqaeeMhUC1SeffCJ//PGHHH/88aa736xZs8w2agvV4sWLZd68eaY7YLNmzcxjXU+3bt3ElwhXQS7d0y2QghYAAADwj6lTp8oll1xiqvBlZGTIzTffLDk5OT5Z19tvv22mygU2rr76apk2bZoZ+6UBS7v+6XxtUVONGzc2AVCfLyoqMoFQuwhq6fbVq1fL119/bcZn6Xbr2Cwt437KKaeILxGuglyGp6AFLVcAAAA4PBpMrHCiTjzxxCrLk+s1pazudZarrrqqwuPK3QSdVbyPjn+qyYIFC6qcry1QGorGjBkj5513XpXLDB06tNrXawvV7Nmzxd8YcxUiY672FpRKWblvmmIBAAAAHD7CVZBrnBArUe5CMHsK6BoIAAAABCvCVZCLjrJJGhUDAQAAgKBHuAoB6YlcSBgAAAAIdoSrEOBpueJCwgAAAEDQIlyFUjn2PMZcAQAAAMGKcBVK5dhpuQIAAACCFuEqhMqx03IFAAAABC/CVQhId7dcZdMtEAAAAAhahKtQGnNFt0AAAAAgaBGuQkAGBS0AAABQTzabrcZpypQp9d63+vqZM2c22HKhzh7oDUBdrnNVzO4CAABAnWzfvt1zf/r06TJ58mRZu3atZ15SUhJ7tIHQchVC3QLzS8qlsKQ80JsDAAAAb06nSEm+/yddby20aNHCM6WmpppWJO9506ZNk27dukl8fLx07dpVnnnmGc9rS0pKZNKkSdKyZUvzfLt27eT+++83z7Vv397cnn322eY927sf15XD4ZC7775bWrduLXFxcdK3b1+ZPXt2rbbB6XSalre2bdua12ZmZso111wTsOOTlqsQkBRnl1h7lJSUOcy4q9axCYHeJAAAAFhKC0Tuy/T//rhtm0hs4mG9xVtvvWVasp566inp16+fLF++XC677DJJTEyU8ePHyxNPPCEfffSRvPvuuybAbNmyxUzqhx9+kGbNmsmrr74qo0aNkujo6Hptw+OPPy6PPvqoPP/882YbXnnlFTnrrLNk0aJF5nFN2/D+++/Lf/7zHxMQe/ToITt27JCff/5ZAoVwFQL0l4CMxFjZtr/IlGNv3YRwBQAAgMN35513mmBzzjnnmMcdOnSQVatWmaCj4Wrz5s3SuXNnGTp0qDkn1VYjS9OmTc1t48aNTQtYfT3yyCNy8803y7hx48zjBx98UObPny/PPvusvPDCCzVugz6n6x42bJjExMSY8DVo0CAJFMJVCJVjN+GKioEAAADBJSbB1YoUiPUehvz8fFm/fr1ceumlprXKUlZWZroPqosvvliGDx8uRx55pGmdOu2002TEiBHSUHJycmTbtm1y7LHHVph/zDHHyLJlyw65Deedd5489thj0rFjR/Pc6NGj5fTTTxe7PTAxh3AVYuOuuNYVAABAkLHZDrt7XiDk5eWZ2xdffFEGDx5c4Tmri99RRx0lGzZskM8++0y++OILOf/8800r0Xvvvee37Tyqhm1o06aNKc6h8+fOnStXXnmlPPzww/LVV1+Zlix/o6BFiEhLdF/rigsJAwAAoAE0b97cFID4448/pFOnThUm7R5oSUlJkbFjx5oQptUGdZzTnj17zHMaYMrL619wLSUlxWzDd999V2H+woULTUtVbbahUaNGprVKx2YtWLDAjNVauXKlBAItVyEiI4ly7AAAAGhYd911l6mup90AtVtdcXGx/Pjjj7J371654YYbZOrUqaZKnxaWiIqKkhkzZpgxTjrOSmmFwHnz5plufXFxcdKkSZNq16WtTz/99FOFeTqW6p///KcZ+3XEEUeYSoFaIEOX0zFXqqZteO2110y405a3hIQEefPNN03Y8h6XFXEtV08//bT5YLS0ou6YJUuWVLusptXjjjvOfHA6aZNg5eW1JKNWPdEPQXeuLrNu3ToJZelWy1V+SaA3BQAAAGHi73//u7z00ksm0PTq1UtOOOEEE1islqvk5GR56KGHZMCAATJw4EDZuHGjzJo1y4QcpcUwtDueds/r169fjevSsKbLeE9anVDDnT73j3/8w2yDlmHXCw5r2DrUNmjA0nyg4a53796me+DHH38s6enpEgg2pyaRANJmvYsuukiee+45E6x0QJqmUe07qaUdK7vwwgvNztNBbhrGtJrIhx9+KL/++qu0atXKLKPztPb966+/bg6MO+64wzQNauUTfU1tBtZpet+/f79pgvS10tJSc4DoALzq+oa+t/RPuXHGz3J8l6byxiWBq4CC4FGb4wbg2AHfOQikcPy3qqioyLTA6Dlmbc4rIfW+9pWek+u5uBXkAvW51iUbBLzlSpv5tDrJhAkTpHv37iZkaZOe1revrha/DlTTJkO9yJkmbd352hypNCtqQLv99tvlzDPPNAn2jTfeMFVINAGHekGL3XnFgd4UAAAAAME25kqvtrx06VK59dZbPfM0mWo3Ph2IVhsFBQXmV5G0tDTzWBOnXjxM38OiSVNbxfQ9rfr53rRvqU7e6VTp++rka9Y6alpX4zhXxZbsvGK/bBOCX22OG4BjB3znIJDC8d8q/Vv0x3z9cV8n+IbT3bnO2te+puvQdennW/liyHU5fgMarrKzs80ANK1U4k0fr1mzplbvoRcc0wojVpjSYGW9R+X3tJ6rTLsQ6mC+yubMmWNa0fxF+6tWZ6/JfnbJzi2STz+dZSp+Aoc6boD6fucAHDdoSOH0faPXT9JiClrGXBsK4Fu5ubl+2cX6WRYWFsrXX39trvNVuTEnIqoFPvDAAzJt2jRTcvFw+rxqy5kOovNuudJBeXpxMn+NudIvHb04WnX9kYtLy2XKsnlS7rTJcScNl5RG4dFvGb49bgCOHTQUvnPAcXNgbM6WLVskKSmJMVc+5HQ6TbDSYhY2P7Qq6OeqhfCOP/74KsdchUS4ysjIMM1uO3furDBfH+svAjV55JFHTLjSiiA6rspivU7fQ6sFer+njtOqipaN1KkyPWH150lrTevT+clxdsktLpP9xQ5JT+FkGoE5ThE+OHbAcQO+b+pOe13pyb5O/ii0EKkc7q6A/trP1mda1b+NdTnPCugRERsbK/379/cUo1BWcYohQ4ZU+zotxXjPPfeYMo1aktGbVvjQgOX9npo2Fy9eXON7hlRRC8qxAwAABIR1ol2XrmIIftbnebg/WAe8W6B2xxs/frwJSYMGDTKV/vLz8031QKVl2rXEuo6Lssqs6zWs3n77bXNtLGsclTbN6qSJ87rrrpN7773XXJTMKsWu47LOOussCWXpSXGycXcBFQMBAAACRHtd6bWVsrKyzGMdn++PbmuRxuFwmHFQ2l3Ply1X2v1Qg5V+nvq5Vi5mEXLhauzYsbJr1y4TmDQoadc9bZGyClJs3ry5wg7VKzXrjj733HMrvI9e1XnKlCnm/k033WQC2sSJE2Xfvn0ydOhQ856hfi0C60LC2XkMngQAAAgUaxiKFbDgm9BTWFhoxkH5I7xqsDrUsKSQCFdq0qRJZqqKFqvwpldkPhT9AO6++24zhRNtuVK7CVcAAAABo+eaOra/WbNmYVVmPpiUlpaayn1aYMLXY8v1/Q+3xSqowhXq1nK1O58LCQMAAASanpA31Ek5KtL9qiXRtedZKBXuosRJKBa0oOUKAAAACDqEqxDsFpidR8sVAAAAEGwIVyEkw9MtkIIWAAAAQLAhXIVkQQtargAAAIBgQ7gKwTFX+wpLpazcddVqAAAAAMGBcBVCmiTEipb5dzpF9hZQ9hMAAAAIJoSrEBIdZZO0BMqxAwAAAMGIcBViKMcOAAAABCfCVYhJT6QcOwAAABCMCFchhpYrAAAAIDgRrkJMhlWOPZ9y7AAAAEAwIVyFmHTrQsJ5XEgYAAAACCaEqxC9kHA24QoAAAAIKoSrEJNmtVzRLRAAAAAIKoSrEJORRLdAAAAAIBgRrkK0W+DuPApaAAAAAMGEcBWipdjzS8qlsKQ80JsDAAAAwI1wFWKS4+wSG+362Bh3BQAAAAQPwlWIsdlsntarPfmUYwcAAACCBeEqBFnhimtdAQAAAMGDcBWC0hOta11R1AIAAAAIFoSrUG65olsgAAAAEDQIVyEog3LsAAAAQNAhXIWg9ETGXAEAAADBhnAVwhcSzqZbIAAAABA0CFchXS2QghYAAABAsCBchSC6BQIAAADBh3AVwt0Cd+cXi9PpDPTmAAAAACBchXbLVWm5U3KKygK9OQAAAAAIV6EpPiZakuLs5j7jrgAAAIDgQLfAEMWFhAEAAIDgQrgK+aIWVAwEAAAAggHhKtSvdZVXEuhNAQAAAEC4Cl0Z7mtd7eFCwgAAAEBQoOUqRKUnusux0y0QAAAACAqEqxAvaJFNyxUAAAAQFAhXoX4hYVquAAAAgKBAuApRGZ5qgRS0AAAAAIIB4SrUW67oFggAAAAEBcJViEpzt1ztLSiRsnJHoDcHAAAAiHiEqxDVJCFGbDYRp1MDVmmgNwcAAACIeISrEGWPjpImCe5xV/nFgd4cAAAAIOIRrkJYOkUtAAAAgKBBuAqHa11Rjh0AAAAIOMJVCMtwVwzclUu3QAAAACDQCFchLLNxI3O7fX9RoDcFAAAAiHiEqxDWMjXe3G7bVxjoTQEAAAAiHuEqhLVMdbVcbaPlCgAAAAg4wlUIy2zsarnaTssVAAAAEHCEqzAYc7Urr1hKyhyB3hwAAAAgohGuQvw6V7H2KHE6RXbmUNQCAAAACCTCVQiz2WwUtQAAAACCBOEqTCoGUo4dAAAACCzCVZiMu9pKUQsAAAAgoAhXIS7TXY59+36udQUAAAAEEuEqxLX0lGOnoAUAAAAQSISrMGm54kLCAAAAQGARrsJkzNU2xlwBAAAAAUW4CpNugfsLS6WgpCzQmwMAAABELMJViEuJj5GkOLu5v41xVwAAAEDAEK7C6lpXVAwEAAAAAoVwFQYYdwUAAAAEHuEqDGS6x13RLRAAAAAIHMJVGGjJhYQBAACAgCNchdWYKy4kDAAAAAQK4SoMtHJf62or17oCAAAAAoZwFQZausPV9n1F4nQ6A705AAAAQEQiXIVRt8DC0nJzMWEAAAAA/ke4CgPxMdGSnhhr7tM1EAAAAIjQcPX0009L+/btJT4+XgYPHixLliypdtlff/1VxowZY5a32Wzy2GOPHbTMlClTzHPeU9euXSXctXSXY9eugQAAAAAiLFxNnz5dbrjhBrnzzjtl2bJl0qdPHxk5cqRkZWVVuXxBQYF07NhRHnjgAWnRokW179ujRw/Zvn27Z/r2228l3FGOHQAAAIjgcDV16lS57LLLZMKECdK9e3d57rnnJCEhQV555ZUqlx84cKA8/PDDMm7cOImLi6v2fe12uwlf1pSRkSHhLtM97mob5dgBAACAgLAHZrUiJSUlsnTpUrn11ls986KiomTYsGGyaNGiw3rvdevWSWZmpulqOGTIELn//vulbdu21S5fXFxsJktOTo65LS0tNZOvWes4nHU1T3GNufpzT75fthmB1xDHDSITxw44bsD3DYJdaRCd59RlGwIWrrKzs6W8vFyaN29eYb4+XrNmTb3fV8dtvfbaa3LkkUeaLoF33XWXHHfccfLLL79IcnJyla/R8KXLVTZnzhzTkuYvc+fOrfdrd2bbRCRaVm3YLrNm/dmg24XgdjjHDSIbxw44bsD3DYLd3CA4z9GhSUEfrnzllFNO8dzv3bu3CVvt2rWTd999Vy699NIqX6OtZzr2y7vlqk2bNjJixAhJSUnxSxrWA2f48OESExNTr/dovmmvvL7uBymObiSjRx/f4NuI4NMQxw0iE8cOOG7A9w2CXWkQnedYvdqCOlzpOKjo6GjZuXNnhfn6uKZiFXXVuHFj6dKli/z+++/VLqPjt6oaw6UfpD8/zMNZX5sMV6vcztxiiYq2S3SUtmQhEvj7OEX44NgBxw34vkGwiwmC85y6rD9gBS1iY2Olf//+Mm/ePM88h8NhHus4qYaSl5cn69evl5YtW0o4a54cJ5qnSsudkp13YPwYAAAAgAioFqhd8V588UV5/fXXZfXq1XLFFVdIfn6+qR6oLrroogoFL7QIxk8//WQmvb9161Zz37tV6sYbb5SvvvpKNm7cKAsXLpSzzz7btJBdcMEFEs7s0VHSPMVdMXBfYaA3BwAAAIg4AR1zNXbsWNm1a5dMnjxZduzYIX379pXZs2d7ilxs3rzZVBC0bNu2Tfr16+d5/Mgjj5jphBNOkAULFph5f/75pwlSu3fvlqZNm8rQoUPl+++/N/fDXcvUeNm+v8hMB/YSAAAAAH8IeEGLSZMmmakqVmCytG/fXpxOZ43vN23aNIlULRs3Etm8j5YrAAAAINK6BaJhtdJwZboFFrFrAQAAAD8jXIVZt0C1fT9jrgAAAAB/I1yFkZap7par/bRcAQAAAP5GuAojmY2pFggAAAAECuEqjGS6x1zpda5KyhyB3hwAAAAgohCuwkh6YqzE2qNECyruzKFrIAAAAOBPhKswYrPZPEUtuJAwAAAA4F+EqzDjCVdUDAQAAAD8inAVpuOuuNYVAAAA4F+EqzCT6S7HzrWuAAAAAP8iXIWZlu5y7Nv3UdACAAAA8CfCVZh2C9y6rzDQmwIAAABEFMJV2HYLpOUKAAAA8CfCVZh2C9xfWCoFJWWB3hwAAAAgYhCuwkxKfIwkxdnNfSoGAgAAAP5DuApDme7WKy4kDAAAAPgP4SoMtaQcOwAAAOB3hKuwbrmiqAUAAADgL4SrMG65olsgAAAA4D+EqzC+1hXl2AEAAAD/IVyFocxUd7fA/VxIGAAAAPAXwlUYamm1XO0rEqfTGejNAQAAACIC4SoMtXS3XBWWlsu+gtJAbw4AAAAQEQhXYSg+JlrSE2PNfboGAgAAAP5BuApTLd3l2LVrIAAAAADfI1yFKS4kDAAAAAR5uCosLJSCggLP402bNsljjz0mc+bMaehtw2Fo5S5q8ec+KgYCAAAAQRmuzjzzTHnjjTfM/X379sngwYPl0UcfNfOfffZZX2wj6qF1E1e42rLnQBAGAAAAEEThatmyZXLccceZ+++99540b97ctF5p4HriiSd8sY2oh3bpieZ2027CFQAAABCU4Uq7BCYnJ5v72hXwnHPOkaioKDn66KNNyEJwaJeeYG437y7gWlcAAABAMIarTp06ycyZM2XLli3y+eefy4gRI8z8rKwsSUlJ8cU2oh7aNHGFq9ziMq51BQAAAARjuJo8ebLceOON0r59ezPeasiQIZ5WrH79+vliG1EPjWKjpVlynLm/iXFXAAAAgM/Z6/qCc889V4YOHSrbt2+XPn36eOaffPLJcvbZZzf09uEwuwZm5RbLpt350rdNY/YlAAAAEGzXuWrRooVppdKxVjk5OaaboI7D6tq1a8NvIeqtbVqiZ9wVAAAAgCALV+eff7489dRTnmteDRgwwMzr3bu3vP/++77YRhxuUQu6BQIAAADBF66+/vprTyn2Dz/80FSi0+tdaRn2e++91xfbiMMMV4y5AgAAAIIwXO3fv1/S0tLM/dmzZ8uYMWMkISFBTj31VFm3bp0vthH11CbtQDl2AAAAAEEWrtq0aSOLFi2S/Px8E66sUux79+6V+Ph4X2wj6qmdO1ztyCmSotJy9iMAAAAQTOHquuuukwsvvFBat24tmZmZcuKJJ3q6C/bq1csX24h6SkuMlaQ4V0HILYy7AgAAAIKrFPuVV14pgwYNMhcRHj58uKkYqDp27MiYqyBjs9mkbVqCrNqeY4padG6eHOhNAgAAAMJWncOV0gqBOmkxC530JF7HXCE4i1pouNrEuCsAAAAg+K5z9cYbb5gugI0aNTKTlmH/73//2/Bbh8PWlnLsAAAAQHC2XE2dOlXuuOMOmTRpkhx77LFm3rfffiuXX365ZGdny/XXX++L7UQ9abdAtWl3PvsQAAAACKZw9eSTT8qzzz4rF110kWfeGWecIT169JApU6YQroJMu7REc8u1rgAAAIAg6xa4fft2OeaYYw6ar/P0OQTnhYT/3FMoDocz0JsDAAAAhK06h6tOnTrJu+++e9D86dOnS+fOnRtqu9BAWqbGiz3KJiXlDnO9KwAAAABB0i3wrrvukrFjx5rrWlljrr777juZN29elaELgWWPjpLWTRrJxt0FpmJgZuNGfCQAAABAMLRcjRkzRhYvXiwZGRkyc+ZMM+n9JUuWyNlnn+2LbcRhapvuGne1eQ9FLQAAAICgus5V//795c0336wwLysrS+677z657bbbGmrb0EDaprlaq7jWFQAAABBk17mqihaz0BLtCD5UDAQAAABCKFwh+C8kvGVPQaA3BQAAAAhbhKsIKsdOt0AAAADAdwhXEaBtmitc7S8slf0FpYHeHAAAACCyC1rccMMNNT6/a9euhtge+EBCrF0ykuIkO69YNu3Jl94JjdnPAAAAQKDC1fLlyw+5zPHHH3+42wMfdg004Wp3gfRuTbgCAAAAAhau5s+f3+Arh/+0S0uQpZv2ymaKWgAAAAA+wZirCKsYuHk3FQMBAAAAXyBcRVrFwD35gd4UAAAAICwRriJE27REc0vLFQAAAOAbhKsIK8e+PadIisvKA705AAAAQNghXEWIjKRYSYiNFqdT5M+9hYHeHAAAACByw9VDDz0khYUHTsq/++47KS4u9jzOzc2VK6+8suG3EA3CZrN5Wq/oGggAAAAEMFzdeuutJkBZTjnlFNm6davncUFBgTz//PMNv4Vo+KIWuylqAQAAAAQsXDm1P1kNjxH82qW7ilps4lpXAAAAQINjzFUEaUO3QAAAAMBnCFcRpJ0Vrmi5AgAAABqcvS4Lv/TSS5KUlGTul5WVyWuvvSYZGRnmsfd4LAT3mCsNVw6HU6KibIHeJAAAACDywlXbtm3lxRdf9Dxu0aKF/Pe//z1oGQSvzMaNJDrKJsVlDsnKLZYWqfGB3iQAAAAg8sLVxo0bfbsl8LmY6Chp1biRabnSioGEKwAAACCMxlw9/fTT0r59e4mPj5fBgwfLkiVLql32119/lTFjxpjl9bpNjz322GG/Z8SWY2fcFQAAABCYcLVo0SL55JNPKsx74403pEOHDtKsWTOZOHFihYsK18b06dPlhhtukDvvvFOWLVsmffr0kZEjR0pWVlaVy+u1tDp27CgPPPCA6ZbYEO8ZqRUDtxCuAAAAgMCEq7vvvtu0HFlWrlwpl156qQwbNkxuueUW+fjjj+X++++v08qnTp0ql112mUyYMEG6d+8uzz33nCQkJMgrr7xS5fIDBw6Uhx9+WMaNGydxcXEN8p6RWjFw0+6CQG8KAAAAEJljrn766Se55557PI+nTZtmutxZRS7atGljWoumTJlSq/crKSmRpUuXyq233uqZFxUVZcKatpLVR33fU1vcvFvdcnJyzG1paamZfM1ahz/W1SrVFUo37s7zy/oQHscNwgvHDjhuwPcNgl1pEJ3n1GUbah2u9u7dK82bN/c8/uqrr+SUU06p0Kq0ZcuWWq84OztbysvLK7yn0sdr1qyp9fs0xHtqi9tdd9110Pw5c+aYVi9/mTt3rs/XsTVf/2uX9Tv2y6xZs3y+PoTHcYPwxLEDjhvwfYNgNzcIznN0aFKDhysNKBs2bDAtVNpCpOOZvAOJXucqJiZGQpG2dOk4Le+WK/07R4wYISkpKX5Jw3rgDB8+3Of7MK+4TB5a8aXkl9nkuJOGS3J8aH5m8O9xg/DCsQOOG/B9g2BXGkTnOVavtgYNV6NHjzZjqx588EGZOXOmadE57rjjPM+vWLFCjjjiiFqvWC8+HB0dLTt37qwwXx9XV6zCV++p47eqGsOlH6Q/P0x/rK9JTIykJ8bK7vwS2ZZTKj2T/dcyB9/w93GK8MGxA44b8H2DYBcTBOc5dVl/rQta6Hgru90uJ5xwghlnpVNsbKzneS0YoS09taWv7d+/v8ybN88zz+FwmMdDhgyp9fv4+j3DUVt3OXa93hUAAACAhmGvS6vQ119/Lfv375ekpCTTQuRtxowZZn5daFe88ePHy4ABA2TQoEHmulX5+fmm0p+66KKLpFWrVp4qhNodcdWqVZ77W7duNYU2dL2dOnWq1XvCVTFw+eZ9VAwEAAAAAhGuLKmpqVXOT0tLq/PKx44dK7t27ZLJkyfLjh07pG/fvjJ79mxPQYrNmzeban+Wbdu2Sb9+/TyPH3nkETNpa9qCBQtq9Z7QlqtEsxs27TbVLQAAAAD4M1xdcskltVqurteTmjRpkpmqYgUmS/v27cXpdB7We0KkczNXC+PqHbnsDgAAAMDf4eq1116Tdu3amZaj2gQcBK+erVytj6u350hpuUNioms99A4AAADA4YarK664Qt555x1Tjl3HL/31r3+tV1dABMeYq+Q4u+QWl8nvWXnSraXvy80DAAAA4a7WTRZPP/20bN++XW666Sb5+OOPzXWgzj//fPn8889pyQoxUVE26Z7pClS/bN0f6M0BAAAAwkKd+oPptaAuuOACc0EvrdrXo0cPufLKK81YqLy8PN9tJRpcL3fXQMIVAAAA0DDqPdhGq/jZbDbTalVeXt5AmwN/j7taScsVAAAA4P9wVVxcbMZdDR8+XLp06SIrV66Up556ypRMr+s1rhAc4WrV9hwpd1CgBAAAAPBbQQvt/jdt2jQz1krLsmvI0gsLIzR1zEiUxNhoyS8pl/W78qRL8+RAbxIAAAAQGeHqueeek7Zt20rHjh3lq6++MlNVPvjgg4bcPvi4qMUPG/eacVeEKwAAAMBP4eqiiy4yY6wQXl0DNVzpuKtzjmod6M0BAAAAIuciwggvPTNd465+3ZoT6E0BAAAAIrdaIEJfr9bucLVtvzgoagEAAAAcFsJVhBe1iI+JMkUt/sjOD/TmAAAAACGNcBXB7NFR0r1liqf1CgAAAED9Ea4iXC/rYsJ/Eq4AAACAw0G4inA93OHqF1quAAAAgMNCuIpwVsuVVgykqAUAAABQf4SrCNepWZLE2qMkt7hMNu0pCPTmAAAAACGLcBXhYqKjpJu7qMUvWxl3BQAAANQX4QrSqxXhCgAAADhchCtIz0yKWgAAAACHi3AF6WlVDNyaI06nkz0CAAAA1APhCtKlebLERkfJ/sJS2bKnkD0CAAAA1APhCqZa4JEtks2e4HpXAAAAQP0QrmD0dBe1WEnFQAAAAKBeCFeoNO6KcuwAAABAfRCuYPTyClcUtQAAAADqjnAFT1ELe5RN9haUytZ9FLUAAAAA6opwBSM+JtoELKskOwAAAIC6IVzhoKIWjLsCAAAA6o5whYPHXW2jqAUAAABQV4SrUJC/W8Th8PlqelDUAgAAAKg3wlUwczpFXh4h8nBHkZ2/+Hx13VumSHSUTbLzSmRHTpHP1wcAAACEE8JVMLPZROJcRSZk03d+KWrRuVmSuU9RCwAAAKBuCFfBrt2xrtuN3/pldT0yXeOuVnIxYQAAAKBOCFfBrv3QAy1Xfhh31YuKgQAAAEC9EK6CXWY/kZgEkcK9IrtW+3x1fds2MbdLN+0Vh8Pp8/UBAAAA4YJwFeyiY0TaDHbd3+j7cVc9M1MkMTZa9heWyuodXEwYAAAAqC3CVShob427+sbnq7JHR8nADmnm/vd/7PH5+gAAAIBwQbgKBe2Pc91uWugqz+5jR3dMN7ff/7Hb5+sCAAAAwgXhKhRkHiVibyRSkC2ya63fwtWSDXsYdwUAAADUEuEqFNhjRdoM9FvXQMZdAQAAAHVHuAoV7bxKsvth3NWA9oy7AgAAAOqCcBVq17vSioF+HHe1mHFXAAAAQK0QrkJFq/4i0XEi+Vkiu3/3+eqO7uhquVrMuCsAAACgVghXoSImXqS1H8ddtUr1XO9qzY5cn68PAAAACHWEq1DtGuhjMRXGXVGSHQAAADgUwlUoXkxYi1pwvSsAAAAgqBCuQol2C4yOFcndLrLnD5+vbjDjrgAAAIBaI1yFkphGIq0GuO5v/Nbnq+vVKlUSGHcFAAAA1ArhKpS7Bvpx3NXiDYy7AgAAAGpCuAo17Y718/WuKGoBAAAA1AbhKtS0GSQSZRfJ+VNk70b/XUyY610BAAAANSJchZrYRNcFhf3UNdAad7WvoFTW7uR6VwAAAEB1CFeh3jXQx7jeFQAAAFA7hKtQLmrhh4qBanAHxl0BAAAAh0K4CkVtjhaxRYvs3yyyb7Pfxl0tYdwVAAAAUC3CVSiKSxLJ7Oe3roG9W6dKo5ho2VtQKr9lMe4KAAAAqArhKlT5sWuga9xVE3P/+/Vc7woAAACoCuEqVLU/znW7yT/jrqyugd//sccv6wMAAABCDeEqVLUZLGKLcl3rav9WP17varc4HL6/eDEAAAAQaghXoSo+RaRlH9f9jd/4fHWMuwIAAABqRrgKZUec5LpdO8vnq2LcFQAAAFAzwlUo63qa63bdXJHSQj92DWTcFQAAAFAZ4SqUaTn2lNYipQUi6+f7LVx993u2lJQ5fL4+AAAAIJQQrkKZzSbSzd16teYTn6+ub5vG0jQ5TnKKykzAAgAAAHAA4SpcugbquKvyMp+uKjrKJqN7tjD3P16xzafrAgAAAEIN4SrUtR0i0ihNpHCvyKbvfL66U3tnmtu5v+6U4rJyn68PAAAACBWEq1AXbRfpOtpvXQMHtGsizVPiJLe4TL75ja6BAAAAgIVwFQ66nu66Xf2JiMO3hSaitGtgr5bm/qcrt/t0XQAAAEAoIVyFg44nisQmieRuE9m23OerO623K1zNXbVTikrpGggAAAAETbh6+umnpX379hIfHy+DBw+WJUuW1Lj8jBkzpGvXrmb5Xr16yaxZFS+ie/HFF4vNZqswjRo1SsJWTLxI5+Gu+2s+9vnq+rVpIpmp8ZJXXCZf/bbL5+sDAAAAQkHAw9X06dPlhhtukDvvvFOWLVsmffr0kZEjR0pWVlaVyy9cuFAuuOACufTSS2X58uVy1llnmemXX36psJyGqe3bt3umd955RyKiaqB2DfSxCl0DV9A1EAAAADDnyYHeDVOnTpXLLrtMJkyYIN27d5fnnntOEhIS5JVXXqly+ccff9wEp3/+85/SrVs3ueeee+Soo46Sp556qsJycXFx0qJFC8/UpEkTCWudR4hEx4rsXieya63PV3equ2vgF6t3SmEJXQMBAAAAeyB3QUlJiSxdulRuvfVWz7yoqCgZNmyYLFq0qMrX6Hxt6fKmLV0zZ86sMG/BggXSrFkzE6pOOukkuffeeyU9Pb3K9ywuLjaTJScnx9yWlpaaydesdRzWuqIbSXT74yVq/RdS/stMcQytuI8aWo8WidKqcbxs3VckX6zaLqN6NPfp+uCj4wYRiWMHHDfg+wbBrjSIznPqsg0BDVfZ2dlSXl4uzZtXPDHXx2vWrKnyNTt27KhyeZ1v0Zatc845Rzp06CDr16+X2267TU455RQTzKKjow96z/vvv1/uuuuug+bPmTPHtKL5y9y5cw/r9W1L2ko/Ecld8rZ8ldNVfO3IhCjZui9KXpm7XBybfFulEL47bhC5OHbAcQO+bxDs5gbBeU5BQUFohCtfGTdunOe+Frzo3bu3HHHEEaY16+STTz5oeW05824N05arNm3ayIgRIyQlJcUvaVgPnOHDh0tMTEz93yh/oDgff00aF26U0cf2FkltLb7UZut++fK5xbImxy4nDjtREmLD8nAKWg123CDicOyA4wZ83yDYlQbReY7Vq602Ano2nJGRYVqSdu7cWWG+PtZxUlXR+XVZXnXs2NGs6/fff68yXOn4LJ0q0w/Snx/mYa+vcaZIm6NFNi+UmN9nixx9hfhSv3bp0jYtQTbvKZBv1u+V03pn+nR9qJq/j1OED44dcNyA7xsEu5ggOM+py/oDWtAiNjZW+vfvL/PmzfPMczgc5vGQIUOqfI3O915eaaqtbnn1559/yu7du6VlS1cRhrDWzeuCwj6mJe6twhZUDQQAAECkC3i1QO2O9+KLL8rrr78uq1evliuuuELy8/NN9UB10UUXVSh4ce2118rs2bPl0UcfNeOypkyZIj/++KNMmjTJPJ+Xl2cqCX7//feyceNGE8TOPPNM6dSpkyl8Efa6nuq63bxQJD/b56s71V2S/cs1Wea6VwAAAECkCni4Gjt2rDzyyCMyefJk6du3r/z0008mPFlFKzZv3myuU2U55phj5O2335YXXnjBXBPrvffeM5UCe/bsaZ7XboYrVqyQM844Q7p06WKuh6WtY998802VXf/CTpN2Ii16izgdIms/8/nqemSmSPv0BCkuc8i81RW7awIAAACRJCgqEGirk9XyVJkWoajsvPPOM1NVGjVqJJ9//rlEtG5niOxYIbL6Y5Gj/ubzroE61uqp+b+broFn9m3l0/UBAAAAwSrgLVfwgW6nuW7/mC9SnOvzXWyNu1rw2y7JLQr8tQgAAACAQCBchaOmXUXSjhApLxFZN8fnq+vaIlk6Nk2UkjKHfEHXQAAAAEQowlU4stlEup/hur/8LT+sztU1UFE1EAAAAJGKcBWujhqvsUdk/TyR7N99vrrT3F0Dv/ptl2zZU/urWAMAAADhgnAVrtI6iHRxl57/4UWfr65L82Q5tlO6lJY75Yl563y+PgAAACDYEK7C2aDLXLc/ve2XwhY3jjjS3L6/7E9ZvyvP5+sDAAAAggnhKpx1PEkkvZNIcY7Iz9N8vrp+bZvIsG7NxOEU+c/c33y+PgAAACCYEK7CWVSUyEB369WSF0WcTp+v8obhrtarT1Zsl1Xbcny+PgAAACBYEK7CXd8LRGISRbLXimz4yuer656Z4iluMXXuWp+vDwAAAAgWhKtwF5/qClhW65UfXD+8i0TZRL5YnSXLNu/1yzoBAACAQCNcRQKra+DaWSL7Nvt8dUc0TZIxR7U296fOYewVAAAAIgPhKhI06yrS4QQRp0Pkh5f9ssprTu4sMdE2+fb3bFm0frdf1gkAAAAEEuEqUgya6Lpd9rpIaaHPV9cmLUHGDWxr7j8yZ604/VBMAwAAAAgkwlWkOPIUkdQ2IoV7RX553y+rnHRSJ4mzR8nSTXtlwdpdflknAAAAECiEq0gRFS0y8FLX/cXP+6Use/OUeBl/THtP65VDL4AFAAAAhCnCVSQ5aryIPV5kxwqRLUv8ssrLTzhCkuLs8uu2HJn96w6/rBMAAAAIBMJVJElIE+l5ruv+kuf9ssq0xFi5ZGgHc//ROWultNzhl/UCAAAA/ka4ijSD3GXZV/1PJNc/LUl/P66DNEmIkfW78uXFb/7wyzoBAAAAfyNcRZrMviJtBos4ykR+eMkvq0yJj5HbT+1u7j/2xTpZvyvPL+sFAAAA/IlwFYmOvtJ1u+gZv7VenXNUKzmhS1MpKXPIze+toLgFAAAAwg7hKhJ1P1Ok9UCR0nyRL+/xyyptNpvcd04vSYyNlh837ZX/fr/JL+sFAAAA/IVwFYlsNpGR97nuL39LZPsKv6y2VeNGcsspXc39B2evkS17CvyyXgAAAMAfCFeRqs0gkR7niIhTZM6//HLdK3Xh4HYyqEOaFJSUy20frhSnn9YLAAAA+BrhKpINmyISHSey4WuRtZ/5ZZVRUTZ54JxeEmePkm/WZcuMpX/6Zb0AAACArxGuIlmTdiJD3MUt5twuUlbil9V2bJok1w/vYu7f+8kqycop8st6AQAAAF8iXEW6oTeIJDYV2bNe5MeX/bbavw/tIL1apUpOUZncPvMXugcCAAAg5BGuIl18ishf/uW6v+ABkYI9flmtPTpKHjq3t9ijbDJn1U6ZtdI/JeEBAAAAXyFcQaTf30SadRcp2ify9cN+2yPdWqbIlX/pZO7f+dEvsnVfIZ8GAAAAQhbhCiLRdpER97r2xJIXRLJ/99temfSXTtK1RbJk55XIuBcWyZ97Kc8OAACA0ES4gkunk0U6DRdxlInMney3vRJrj5JXJwyUdukJsmVPoYx74XuufwUAAICQRLjCAdp6ZYsWWfupqzy7n7RMbSTTJw6RDhmJ8udeAhYAAABCE+EKBzTrKjJgguv+J9eLFOX4be+0SI2XaROPlo4ZiWbs1djnF8nm3XQRBAAAQOggXKEirRyY0kpk9+8iH00ScTr9toeap7gDVtNE2ba/SMa+sEg2ZufzCQEAACAkEK5QUUKayHmviUTZRVb9T2Txc37dQ83cAatTsyTZvr/IjMHaQMACAABACCBc4WBtBomM+Lfr/pzbRTYv9uteapYcL+9cdrR0bpYkO3I0YC2SVdv810URAAAAqA/CFao2+P9Eepztqh4442KRvF1+3VNNk+PknYlHy5HNk2VnTrGMeXahzFq5nU8LAAAAQYtwharZbCJnPCmS0UUkd5vI+5eKOMr9urcykuLk3f8bIsd1zpDC0nK58q1l8uicteJw+G8cGAAAAFBbhCtULy5Z5Pw3RGISRDZ8JbLgfr/vrdSEGHn14oFy2XEdzOMnv/xdJv53qeQWlfp9WwAAAICaEK5Qs2bdRE5/wnX/64dFfpvj9z1mj46Sf53aXR49r4+56PAXq3fKOc8spJIgAAAAggrhCofW+zyRgX933f/gMpG9mwKy18b0b226CTZPiZN1WXlyxlPfyte/+XcsGAAAAFAdwhVqZ+R9Iq36ixTtE3lnnEjuzoDsub5tGsvHk4ZKv7aNJaeoTC5+dYnc9uFK2bG/KCDbAwAAAFgIV6gde5zr+ldJzUWyVom8MlJkz4aA7D29FpaWaj+vf2vR2hZvL94sxz88X+75ZJXszisOyDYBAAAAhCvUXuO2IpfMFmncTmTvBlfA2vFLQPZgfEy0PHxeH5k+8WgZ2L6JlJQ55OVvN8hxD82XRz5fK/sLKXgBAAAA/yJcoW7SOopcOkekWQ+RvJ0ir40W2fx9wPbi4I7pZhzWaxMGSq9WqVJQUi5Pzf9djnvwS3l6/u9UFQQAAIDfEK5Qd8ktRCZ8KtLmaJGi/SJvnBWQKoIWm80mJx7ZTD6adKw899f+0qV5khmP9fDna+WY+7+Uez9ZJX/uLQjY9gEAACAyEK5QP42aiPztQ5FOw0XKCkWmXSCyYkZA96aGrFE9W8hn1x4vj43tK0c0TZTc4jJ56dsNcvxD8+Wqt5bJ0k17A7qNAAAACF+EK9RfbILIBe+I9DpfxFEm8sHfRRY+JeJ0BnSvRkfZ5Kx+rWTu9SfIqxMGytBOGabwxacrt8uYZxfK2c98J5+s2Cal5Y6AbicAAADCiz3QG4AQFx0jcvbzrpasJc+LzPmXyO9fiJzxpEjjNgHdtKgom/zlyGZmWrMjR17+ZoP876dtsnzzPpn09nLJSIqVM/u2kjFHtZbumSkB3VYAAACEPlqu0ABHUZTIKQ+KjHpQxB4v8sd8kWeGiCx7I+CtWJauLVJMdcHvbjlJrjm5swlW2XklpsLg6Ce+kVGPfS0vffOH7MqllDsAAADqh5YrNAybTeToy0U6DRP535UiWxaLfHS1yKr/iZz+hEhqq6DY002T4+SG4V3k6pM6yde/7ZL3l/0pX6zKkjU7cuXeT1fL/Z+tkeM7Z8ixnTKkfXqitM9IkDZpCRJnjw70pgMAACDIEa7QsDI6iUz4TOT7Z0Tm3ePqIqitWKPuE+l7oSuEBYGY6Cg5uVtzM+0rKJGPV2yXD5b9aboMzl+7y0wW3eTM1EYmaLVLT5RuLZKlX9sm0rVFstijafwFAACAC+EKDS8qWuSYq0U6jxSZeYXI1h9F/neVyC/vi5w8WSSzX1Dt9cYJsfK3o9uZaf2uPPnk5+3yW1aubMzON1N+Sbls3Vdopu9+3+15XUJstPRp3Vj6t2tipn5tG5v3AgAAQGQiXMF3mnZxXXB44ZMi8+8TWf+la9LQdeLNIq36B93eP6Jpklw7rLPnsdPplN35Ja6gtbtANmTnyYo/98tPm/eZMu+L/thtJkurxo2kTVojadPE1Z3Q+37TpDhTZAMAAADhiXAF37diDb1OpNvpIl89KLJyhsi6z12TXiPrxFtEWg8I2k9Br52VkRRnpgHt0zzzyx1O+T0rT5Zt3muunaW3f+zK97RwfS97Dnove5RN0pNiJT0xztzqe6Ynxkq63ibFSlpCrKR53SbH2c36AQAAEBoIV/CP9CNEznlB5PibRL55RGTFuyK/z3VNR5wkcvw/RdoOCZoxWbW5ltaRLZLNdMGgtmbe3vwS061wy94C2bKnULbsKZA/9xaax9v3F0mZwyk7c4rNVBsaxpokusJWaqMYSWlkl5R4vXVNSbFRsjHLJsnrsqVVWpI0T4kzyxHIAAAAAoNwBf8XvDj7OVeY+uZRkZ+nHegu2KSDSM8xIr3OFWnWLeQ+GQ1CAxLTKrRwWfSCxdl5xbI7r6Tibf6Bx3sLSmRPvmsqKCk3YUxLw9dcHj5a3l6/zPMozh4lzVPipUVKvDRNiTOtX/Ex0WZqpFNslLnVxxnJcdIyNV5apjQywY1QBgAAcHgIVwhcS9ZZz7hC1rdTRVa+J7J3g6tVS6dmPUR6jXGFrSbtQ/5T0uqELVMbmak2ikrLTdiyQlduUZnsLyyVHJ2K9LZM9hUUy7pN20TiU2RnbrHsLSiV4jKHbN5TYKa60MClQauFe9KS9Rnu7otpie4ujO77lKUHAACoGuEKgZXWQeSMJ0VG3i/y22xXyNLy7Vm/iszT6W5X4YuOJ4q0O1akzWCRuKSw/9S0ZelQYay0tFRmzfpTRo8+RmJiYkwg01aunTlFsiOnSLJyiqWwtFwKS8pdt6XlUlRSLkVl5ZJf7FpWl9OWMn3uj+x8Mx1KTLRNomw20zUy2mYzRTr0vmueVJin97Wnp97XgJkYa5fEuGhJiLNLUqxdEuKiJSnOLo1ioyXe7mpR09a3uJgo81hvNfgl6vJxdkmO19fbzXsBAAAEG8IVgoMGJu0OqFPBHpHVH4v88p7Ihm9Eti51TdqN0BbtKuXe7hiR9kNF2h4tEp8a6K0PChpMXBUKE+r0Og1lGsh0XNiO/UWybX+hZOdq90Sr26K2oBWbEKZdFUvLnVpHUQIpPiZKkuJiTNjScWZNEnSKlVT3rT5OTXAVBdEwpmXz9TbRfauBzarcqBUhHU4Rh9MpTvetBjy6SQIAgLoiXCH4JKSJ9B/vmnJ3iKybK7LpO5GN34ns3+y6bpZOC5/Qen6uLoYteok07ynSorfrfnKLkCmOEQyhTC+OrFNNNIRo10Rt5dJqiQ6HSLnT6brvvvW+73CHFteyTikud0hBcbnkl5RJQXGZuX5YfnGZGV+mt0VlDinW1rVKt7o+fV67Rmq3R1VU6pCi0mIzXq2+9PDQMFWVWLt243SNXXN1l9RWRFeXSQ1sVhjzDmQ6T9mjbRITFeW6jbaJ3X1fA51WimR8GwAA4YtwheCmIemov7kmtW+zyKaFIhu/dQWuPX+I7P7dNf364YHXJWSItOgpknaESJN2Io3bHbht1ITgVQ/akqMXSW4sgVNS5jBBK88dtnT8mQa+fQU6Nk1vrfsl5r4ryJVXuLVCUHXBylrPpt0FZmpoGrh07Jp3SX5tfdNAZ7pPmi6VrkCmj7VqZJwWITHdJV23VpESbWHTLpKxdle3S3u0PnaFuxh7lMS6H9MKBwCAfxCuEFoat3VNfca5HuftEtm5UmSH15T9m0hBtsgfC1xTZXEprpCVkimS0lIkWacWFW8bpYlE879HsNEAEmuPNZUZ60Nb37TVyxWynGacmE7axqm3ekdv9heUmm6S2/cXmq6SVpdJfawtaeY15rWu8WTWfQ1sZQ6HlJVr90mH6Uap90vKHWbsm4ZC7VZZl5L8h0v/HjOOzR5t9l+cO3SVFUbLu1lLTVdKT4n/eLu5TYi1u1/jCnSe+/Zo15g79xg7/ZvNrXnsKtyiXTUpegIAiFScPSK0JTUVSTrJda0sS2mhSNYqkZ2rRPZuFNm3SWSvThtF8rNEinNcgUynmsSlijTSqcmBKb6xa4xXfIorpOl9c+t+HJcsEpskEpsoYo+jhSzIaAjS4hk61UTDRl3HrtV2fJuOXTOl+POLZY+OZ8t3VXosdwcxE860i6UGNIfDhLGSsnJ3V8hy0zXS+7bUCnLlDik1Y+IcFVrl9L7rtY7Ke0M2r98tvqAhToNasoY2960WJNGxcp5WN3fRkgMtcDbT8uYqfuJqvdNWPJ2nXSq1+ImOnUuIsXvu63xa5QAAwYRwhfAT08hVYVCnykoKXF0Ldcrd5hrTlbu94m1elqtgQ/F+16TL1keU3RWyrLAVk+Ce4l239vhK9xu5Jnujg+frrbW8dV/sYi8vFCkvEbHbCXIhQINEZuNGZvIlDWratVFbzIrLyqW41H2/1PU4v6hEvlq4WI7s0UfyS50VSvzrrY6D0+X0PYo9k+t9NLyZMWfe4+rM2DOr2ImrW6UWQtHJL62Z7u6PsVY3SdNV0tXq1shdcdJUpIw5EMo0vGmrnra4adulqW/ibo0zXTHd1SqtFjuriqV5nbtFUF/nbvA0NAh6V7XU+7odAIDIQbhCZIlNEGnW1TVVp7xMpGi/SOHeA1PRPtetVjLUlq+iHFfwMrfWY53yRMoKXe/jcL+PTj4QIyKn6p0V/+eaER0rEh0nEh3jajXTW/NY59vdt7Hu+bEiUXprd9/GuMKgua382H5g8jyOrjhfqzjqPOu9PbdV3Y87eH4UJ6ANSVt/TAudRLuPlIPL+O9e7ZTRfTNNGf+GDHV57rFw1ri43KJS121xmatQiZlcrW56WQC9r+GtzNON8kB3ShMS3V0qC0rLzK1eRkC7ZlpMiHQXOglGGq60CIp+HlaNHSuUue67WlS9u156hzp9vXWZg8rdUa1LImgYtHu19kW7x92Z1kHvi4ib+9Y8VxC1JhNQrbF77q6uAIC6I1wBlWngSEx3TfWh4aw0X6TEmvJcoau0wNVlUScNYKVFrnllRV7zi6pZptj1nHnefVteacyOtmDpFIpslcKahq3Koa66cKahzhZ1YPI8tt7THfoqvL81uUOh97IVbmNq8R66fd6PYyotb4VYK4TavbYxvE5g9URfx3Dp5EvaaqYBS1vYtCVNw5W59dx3tdxpgPNc4837mm8l5SbAWZUeK5fk11BntdZ5Wu/crX763uZiBJ7XaTu3674+p6FSA6YVAPX1u8tKRA59CbmgoYeldwugp1UwyiaFBdHy0ubvJdY9/s4TzExBlUrXvzO3rlBoFWbRZc24P68xfTrPNXZRKrzec+08LfDifuxd6MVzvT33mD9rDKX1Xp4WTHdI1fkA4GuEK6ChmVaiVJ9ff6u0pFhmf/qRjBr2F4mxad8sDWDFIuWl7vslIo5Sd+iybr3vl7pa18xtaRWPy1yPPc+Vu+6beWXux973y13vay1feX3e26Ov8ebU1+rknyIPQcNq8attYDsoGFpBzQqJVriMrjE8RjlFum/dJFHzl4nYY7ye9w6lXq+v0ErpvQ73rZlXKdB6v6d366a5tZattO2ewGmrFJi9Qrf2uI2yua5bFhe8/4RpC5y2suUWu1rxNAgqVyY7EMyUhjpXiHONpavclbPcq+y/92UONGSa8XnusXk6Xk+fN/dNl9ADAdNqLbTCpYZRE0LdgdSbrsfTInjQ/5I22V6QI6FIA5kV6rQLp2kBdLcGegKaO7i5qnBW7GZqXVrBYoVqb66WxQNhz9X11BUYXZdncAVFXX+s1zhD1+fm/hzNrWsMpd7XAjPa1dQ1ua7vl+K+1fXp52+19OprrMfRNXVvtdkqXFJCL61h3dftdb3G1cKptwRToPaC918mADWzRYkjKtYV4hqwa5dfmItkVQpfGrAOCm0a9qyAV0U41DDpdLhfW+6+73DfL/cKhFW8p2d9OjkqPm/Cntdjz3ZVES49wdO9nd7bbC1bHU+o9G+Lo3YW7Kx3dHhhSLEd3ILoHcIqTLaDWzI9IbCacGcFSWtZ7/epcaocBqPFbouSVFu0pB60HV7bctB2eoVZnaeFV+IqbWflYKu3VpnLarfXCsVVb79TbFLutEmp09X6VuqwidY/MZMGMIeYqbC4TBb/uFx69u0nDomusEyx3uqhr+8lNilzRIlGNuv6d1YXT0+I1JZAr3GA1gm+CZLW9fLcAdJ6vYZHDQQmRJow6RU03S2OVgDV99FgYl16QZnuptrF1B10UXsaLK1qoVaFVKvKqhm36G6l1PBZuatqtFZg3Rstb23/ocruplZLqdWiaYVZ131X8SH9fF0/HriPCfdxIl5jJl2VS62A69oWT+tqpaBsts3dQqrbarWAVm41NcHbKzCbv7uGBlArOFsB/UCBHpurlds6Vt3jVK1j1xW+D7zO+3qJppJtdd+INWxL5ZBPV1//IVwB8D/TmuEu0BHuzL+mlQKZFQCtIHdQWPMKc/rYWuagwOdezhMu9dYKm97PucOje7nyshLZsP536dC+nUTrKXCF11vTgeUPXp+jhvV6v/YQ87xva7czQ7v7a5CyuU8GdDpUqZXB+p+61PipHCSt8h9V3TfLuLfIConerZgmXOoZfOUA6d1qa6uwTqe20IgGPT251fuuSQOl6d5pbqO87uutKxg6dHnzGg19rlt9bG2XvrfTuu/eZr3VZSq8n3u9+h7l7uet+2VmHfpSPRF33XoudRDlGm9XouFVJx3Gq62RZU73rasNVF9jM4HH9Xfr682Pb/r+ppKoq0XL+1b/Fj3Z1m10nXRb+9xm/hc1LWCmy6vrM9K/walfRaXW/nPtM2vf6qTv4b1/vecl6rx87/3ifl/356INpEVSzfPu+bou63nrfQ8s51LxdRUfe8+v/F6u7r2VjwvXfam0Hutvq/x85ddVte6aeL/uwN/WcF1ZrVZUK3B5B0G71wXv9TnrxworyJpQ625q9w6sB1p1XUHWtR/F/EdbdvXY1hBp9rn7vqv13fu+q5XVc61G9/aYcGoTKd0fJaMltBCuAMCXzEASd5GQIOEoLZVfi2dJuxGjJTpYWj2tn3Wt1kfzr3OlEOcJnqUHHlvLVZ5MiHMHOe/38TxXOeB5B16v9/G8v9f2HHKdXuv1rNt6D6/5FZ7z/ltrCrHe93Vb3dtitqnydnmtr7pt87ym0mur+hvr9bnWJTw3PD011baPmi++EIFJuiaaF6kxFFRMqPcKd5UDnCvgHSogVp4nYjO/GIjYyip2cXWFZCuAHgjQZn3uzhgH3qUip7UO56EDp/fy3n+f9zJZUU1FZJSEkqAIV08//bQ8/PDDsmPHDunTp488+eSTMmjQoGqXnzFjhtxxxx2yceNG6dy5szz44IMyevSBXKtp+M4775QXX3xR9u3bJ8cee6w8++yzZlkAQBBy/2rOWV3wKi0pkVmzPpXRp4ySGL38Q1WhrMpgV14xAFonZdZ9ZxWPKy/vHUI966wqwOptpeUrB0VHpfc+6Na9jgqvq2K7qgrfFd5Hqlm2ilDu2gEV90OFfVLVvq5mfx0Uhr3fy2ubKuz7Su/n/Vzl5SpsT3Wh/MA2OR0OycnZLynJyQdOoavd91X9TdW9xv03em/nQcdVNZ9HnW+93j8AonRctUfgtqNObA3zNun20OvGG/BwNX36dLnhhhvkueeek8GDB8tjjz0mI0eOlLVr10qzZs0OWn7hwoVywQUXyP333y+nnXaavP3223LWWWfJsmXLpGfPnmaZhx56SJ544gl5/fXXpUOHDiaI6XuuWrVK4uMjoBsSAAANzTM+zF3BE6iFstJSWTBrlvkRvCEv/RAw3q29Vf4YIDXcr/INq/6hwXpP63F1P0rUJhhWNb/CgC3v+9X9IOC+X9NAr0MFWVXr+yJlZWWy+sflMkRCS8DD1dSpU+Wyyy6TCRMmmMcasj799FN55ZVX5JZbbjlo+ccff1xGjRol//znP83je+65R+bOnStPPfWUea22WmlAu/322+XMM880y7zxxhvSvHlzmTlzpowbN+6g9ywuLjaTJScnx3MtGJ18zVqHP9aF8MFxA44d8J2DYBf+/1ZZnU8rZRQq/x82PWb2rs4LimOnLtsQ0HBVUlIiS5culVtvvdUzTwdwDhs2TBYtWlTla3S+tnR501YpDU5qw4YNpnuhvoclNTXVtIrpa6sKV9oKdtdddx00f86cOZKQkCD+oiER4LgB3zkIZvxbBY4bRNp3TkFBQWiEq+zsbCkvLzetSt708Zo1a6p8jQanqpbX+dbz1rzqlqlMw513YNOWqzZt2siIESMkJSVF/JGG9cAZPnx4eDSZwy84bsCxA3/iOwccN4jU75wcd6+2kOgWGAzi4uLMVJl+kP78MP29PoQHjhtw7IDvHAQ7/q1CKB87dVl/QIttZmRkSHR0tOzcubPCfH3cokWLKl+j82ta3rqty3sCAAAAwOEKaLiKjY2V/v37y7x58zzzHA6HeTxkSNW1QXS+9/JKmwyt5bU6oIYo72W0KW/x4sXVvicAAAAAHK6AdwvUsU7jx4+XAQMGmGtbaaW//Px8T/XAiy66SFq1amWKTqhrr71WTjjhBHn00Ufl1FNPlWnTpsmPP/4oL7zwgnlerzR+3XXXyb333muua2WVYs/MzDQl2wEAAAAgLMPV2LFjZdeuXTJ58mRTcKJv374ye/ZsT0GKzZs3mwqClmOOOcZc20pLrd92220mQGmlQOsaV+qmm24yAW3ixInmIsJDhw4178k1rgAAAACEbbhSkyZNMlNVFixYcNC88847z0zV0daru+++20wAAAAAEPZjrgAAAAAgXBCuAAAAAKABEK4AAAAAoAEQrgAAAACgARCuAAAAAKABEK4AAAAAIFxKsQcbp9NpbnNycvyyvtLSUikoKDDri4mJ8cs6Efo4bsCxA75zEOz4twrhcOxYmcDKCDUhXFUhNzfX3LZp06ahPxsAAAAAIZoRUlNTa1zG5qxNBIswDodDtm3bJsnJyeaCxP5IwxrktmzZIikpKT5fH8IDxw04dsB3DoId/1YhHI4djUsarDIzMyUqquZRVbRcVUF3WuvWrcXf9MAJ9MGD0MNxA44d8J2DYMe/VQj1Y+dQLVYWCloAAAAAQAMgXAEAAABAAyBcBYG4uDi58847zS3AcQO+cxCM+LcKHDfgO+fQKGgBAAAAAA2AlisAAAAAaACEKwAAAABoAIQrAAAAAGgAhCsAAAAAaACEqyDw9NNPS/v27SU+Pl4GDx4sS5YsCfQmIYjcf//9MnDgQElOTpZmzZrJWWedJWvXrq2wTFFRkVx11VWSnp4uSUlJMmbMGNm5c2fAthnB54EHHhCbzSbXXXedZx7HDaqydetW+etf/2q+Txo1aiS9evWSH3/80fO80+mUyZMnS8uWLc3zw4YNk3Xr1rEzI1x5ebnccccd0qFDB3NcHHHEEXLPPfeY48XCsYOvv/5aTj/9dMnMzDT/Js2cObPCTqnNMbJnzx658MILzYWFGzduLJdeeqnk5eUFzc4lXAXY9OnT5YYbbjCl2JctWyZ9+vSRkSNHSlZWVqA3DUHiq6++MsHp+++/l7lz50ppaamMGDFC8vPzPctcf/318vHHH8uMGTPM8tu2bZNzzjknoNuN4PHDDz/I888/L717964wn+MGle3du1eOPfZYiYmJkc8++0xWrVoljz76qDRp0sSzzEMPPSRPPPGEPPfcc7J48WJJTEw0/25pWEfkevDBB+XZZ5+Vp556SlavXm0e67Hy5JNPepbh2EF+fr4519WGharU5hjRYPXrr7+ac6JPPvnEBLaJEycGz851IqAGDRrkvOqqqzyPy8vLnZmZmc77778/oNuF4JWVlaU/Azq/+uor83jfvn3OmJgY54wZMzzLrF692iyzaNGiAG4pgkFubq6zc+fOzrlz5zpPOOEE57XXXmvmc9ygKjfffLNz6NCh1e4ch8PhbNGihfPhhx/2zNNjKS4uzvnOO++wUyPYqaee6rzkkksqzDvnnHOcF154obnPsYPK9Dzlww8/9DyuzTGyatUq87offvjBs8xnn33mtNlszq1btzqDAS1XAVRSUiJLly41TZ6WqKgo83jRokWB3DQEsf3795vbtLQ0c6vHkLZmeR9HXbt2lbZt23IcwbR6nnrqqRWOD44bVOejjz6SAQMGyHnnnWe6Iffr109efPFFz/MbNmyQHTt2VDieUlNTTZd2/t2KbMccc4zMmzdPfvvtN/P4559/lm+//VZOOeUU85hjB4dSm2NEb7UroH5PWXR5PX/Wlq5gYA/0BkSy7Oxs00e5efPmFebr4zVr1gRsuxC8HA6HGTOj3XZ69uxp5ukXUWxsrPmyqXwc6XOIXNOmTTPdjbVbYGUcN6jKH3/8Ybp2aXf12267zRw711xzjfmOGT9+vOc7pap/t/i+iWy33HKL5OTkmB/3oqOjzfnNv//9b9OFS3Hs4FBqc4zorf7w481ut5sfnIPlO4hwBYRYK8Qvv/xifg0EarJlyxa59tprTZ90LZYD1PYHHP1F+L777jOPteVKv3N0/IOGK6A67777rrz11lvy9ttvS48ePeSnn34yPwZq4QKOHUQSugUGUEZGhvl1p3JVN33cokWLgG0XgtOkSZPMwM358+dL69atPfP1WNEupvv27auwPMdRZNPuoloY56ijjjK/6umkxU50oLDe118COW5QmVbo6t69e4V53bp1k82bN5v71r9N/LuFyv75z3+a1qtx48aZCpN/+9vfTNEcrXjLsYPaqM33i95WLvpWVlZmKggGy7kz4SqAtJtF//79TR9l718N9fGQIUMCuWkIIjrmU4PVhx9+KF9++aUpc+tNjyGt7OV9HGmpdj0Z4jiKXCeffLKsXLnS/HpsTdoioV10rPscN6hMuxxXvtSDjqFp166dua/fP3oC4/19o13BdKwD3zeRraCgwIx78aY/IOt5jeLYwaHU5hjRW/0xWX9AtOi5kR5nOjYrKAS6okakmzZtmqmC8tprr5kKKBMnTnQ2btzYuWPHjkBvGoLEFVdc4UxNTXUuWLDAuX37ds9UUFDgWebyyy93tm3b1vnll186f/zxR+eQIUPMBHjzrhbIcYOqLFmyxGm3253//ve/nevWrXO+9dZbzoSEBOebb77pWeaBBx4w/07973//c65YscJ55plnOjt06OAsLCxkp0aw8ePHO1u1auX85JNPnBs2bHB+8MEHzoyMDOdNN93kWYZjB7m5uc7ly5ebSWPI1KlTzf1NmzbV+hgZNWqUs1+/fs7Fixc7v/32W1MR94ILLgianUu4CgJPPvmkOTGOjY01pdm///77QG8Sgoh++VQ1vfrqq55l9EvnyiuvdDZp0sScCJ199tkmgAE1hSuOG1Tl448/dvbs2dP88Ne1a1fnCy+8UOF5LZd8xx13OJs3b26WOfnkk51r165lZ0a4nJwc8/2i5zPx8fHOjh07Ov/1r385i4uLPctw7GD+/PlVntNoOK/tMbJ7924TppKSkpwpKSnOCRMmmNAWLGz6n0C3ngEAAABAqGPMFQAAAAA0AMIVAAAAADQAwhUAAAAANADCFQAAAAA0AMIVAAAAADQAwhUAAAAANADCFQAAAAA0AMIVAAAAADQAwhUAAA3MZrPJzJkz2a8AEGEIVwCAsHLxxRebcFN5GjVqVKA3DQAQ5uyB3gAAABqaBqlXX321wry4uDh2NADAp2i5AgCEHQ1SLVq0qDA1adLEPKetWM8++6yccsop0qhRI+nYsaO89957FV6/cuVKOemkk8zz6enpMnHiRMnLy6uwzCuvvCI9evQw62rZsqVMmjSpwvPZ2dly9tlnS0JCgnTu3Fk++ugjP/zlAIBAIlwBACLOHXfcIWPGjJGff/5ZLrzwQhk3bpysXr3aPJefny8jR440YeyHH36QGTNmyBdffFEhPGk4u+qqq0zo0iCmwalTp04V1nHXXXfJ+eefLytWrJDRo0eb9ezZs8fvfysAwH9sTqfT6cf1AQDg8zFXb775psTHx1eYf9ttt5lJW64uv/xyE5AsRx99tBx11FHyzDPPyIsvvig333yzbNmyRRITE83zs2bNktNPP122bdsmzZs3l1atWsmECRPk3nvvrXIbdB2333673HPPPZ7AlpSUJJ999hljvwAgjDHmCgAQdv7yl79UCE8qLS3Nc3/IkCEVntPHP/30k7mvLVh9+vTxBCt17LHHisPhkLVr15rgpCHr5JNPrnEbevfu7bmv75WSkiJZWVmH/bcBAIIX4QoAEHY0zFTuptdQdBxWbcTExFR4rKFMAxoAIHwx5goAEHG+//77gx5369bN3NdbHYulXfks3333nURFRcmRRx4pycnJ0r59e5k3b57ftxsAENxouQIAhJ3i4mLZsWNHhXl2u10yMjLMfS1SMWDAABk6dKi89dZbsmTJEnn55ZfNc1p44s4775Tx48fLlClTZNeuXXL11VfL3/72NzPeSul8HbfVrFkzU3UwNzfXBDBdDgAQuQhXAICwM3v2bFMe3Zu2Oq1Zs8ZTyW/atGly5ZVXmuXeeecd6d69u3lOS6d//vnncu2118rAgQPNY60sOHXqVM97afAqKiqS//znP3LjjTea0Hbuuef6+a8EAAQbqgUCACKKjn368MMP5ayzzgr0pgAAwgxjrgAAAACgARCuAAAAAKABMOYKABBRnE5noDcBABCmaLkCAAAAgAZAuAIAAACABkC4AgAAAIAGQLgCAAAAgAZAuAIAAACABkC4AgAAAIAGQLgCAAAAgAZAuAIAAAAAOXz/H91oyKhJ7ugPAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of the train and test losses for convergence check\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history['epochs'], history['hybrid']['loss'], label='Train Loss')\n",
    "plt.plot(history['epochs'], history['hybrid']['accuracy'], label='Test Loss')\n",
    "plt.title(\"Quantum Model Training Progress\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"training_curve.png\")\n",
    "print(\"\\nTraining curve saved as 'training_curve.png'\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pushq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
